{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d265fc5",
   "metadata": {},
   "source": [
    "# 11 Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec127bd7",
   "metadata": {},
   "source": [
    "## 2 - Lineer Regresyon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a5866c",
   "metadata": {},
   "source": [
    "### 1- Doğrusal Regresyon (Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23c633d",
   "metadata": {},
   "source": [
    "amaç bağımlı ve bağımsız değişkenler arasındaki ilişkiyi doğrusal olarak modellemektedir. y = b + wx w burada ağırlıklardır, be ise sabit ifadedir.\n",
    "bağımsız değişken sayısı arttıkça kat sayıları da değişeceğinden bu değişkenlerin veriyi etkileme oranı da değişecektir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd68f34",
   "metadata": {},
   "source": [
    "### 2- Ağırlıkların Bulunması"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4f8c3f",
   "metadata": {},
   "source": [
    "değişkenlerin ağırlıklarına göre etkileri biçimlendirilebiliyor demitik. o zaman bu ağırlıkları nasıl bulabiliriz? gerçek değerler ile tahmin edilen değerler arasındaki farkların karelerinin toplamını ortlamasını minimum yapabilecek b ve w değerini bularak.\n",
    "yi(şapkalı y) = b + wxi \n",
    "sabit bdir ağırlık(katsayı) wdir. öyle bir şekilde bulunmalı ki bu en uygun değerlere sahip olsun. sonuçta bir evin m2sini girdiğimde onu bir değer ile çarpıyor olacağım(w) ve üzerine sabit ekledikten sonra evin fiyatını bulabilirim. ancak bu sabit ve w yi nasıl bulacağım? \n",
    "\n",
    "örn m2(xi) ile fiyat(yi) (tablo ve grafik var) arasında doğrusal bir ilişki olduğunu düşünüyoruz ve 2 boyutlu şekilde grafik haline getirdik. bu iki ilişki değişken arasındaki ilişkiyi doğrusal bir şekilde ifade edebilirsek görmüş olduğumuz doğrusal formda m2 bilgilerini fonksiyona sorarak ev fiyatlarını tahmin edebiliriz. grafikte noktalarımın arasından kırmızı bir doğru geçiyorum yukarıya eğimli olan. bu bir tahmin fonksiyonudur. bu fonkiyon kullanılarak veriden öğrenilmiş olan sabit ve ağırlığa göre tahminlerde bulunma imkanı yakalıyor olacağız. dolayısıyla model dediğimiz şey aslında bu kırmızı doğrudur. yani model dediğimiz şey bu sabitten ve ağırlıktan oluşmaktadır. bir bağımsız değişken değeri geldikten sonra onu yerine yazdıktan sonra verinin tamamından öğrendiğimiz ağırlık ağırlık değeri ile çarpacağız ve bu sabit değer ile topladığımızda belirli bir m2 fiyatına karşılık fiyatın ne olabileceği bilgisine erişeceğiz. peki bu sabiti ve w ifadesini nasıl bulacağız? yani bu doğruyu nereye koyacağız sorusu ile b yi ve w yi nasıl bulacağız sorusu aynı sorudur. burada problem doğru optimum noktaya nasıl koyulacağı problemidir. eğer bu nokta anlaşılırsa makine öğrenmesi problemi büyük ölçüde anlaşılacaktır. tahmin fonksiyonumuzun yüksekliğini b değeri belirler, eğimini ise w ifadesi belirlemektedir. dolayısıyla doğrunun nereye konacağı bu sabit değere ve ağırlığa bağlı olmaktadır. nasıl bir şey yapmalıyım ki bu krımızı çizgiyi en doğru yere yerleştirebileyim? bunu en doğru şekilde yerine koymak için bir cost fonksiyonu tanımlamam gerekmektedir.(bu fonksiyon mse fonksiyonudur) bu fonkiyonun toplam sembolünün başındaki 1/2m ifadesi farklıdır sadece bu da optimizasyon işlemleri ile alakalıdır. yani tahmin edilen değerler ile gerçek değerlerimin farkının karesi alınıp toplanmış ve bunun ortlaması alınmıştır cost fonksiyonu sonucunda. cost(b,w) ,yani ortalama hatamızdır. burada fonksiyonda b ve w değerlerini iteratif şekilde sürekli deneyerek yani değerlerimi fonksiyondan geçirerek sürekli koyulması gereken yere koyarak sonunda optimum nokayı bulacağım. yani elimdeki veri kadar sabit v eağırlığı değiştirmiş olacağım. burada en düşük hata oranını veren sabit ve ağırlığı seçerim.\n",
    "sabit = bias, beta, sabit denmektedir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d7800",
   "metadata": {},
   "source": [
    "### 3- Regreasyon Modellerinde Başarı Değerlendirme (MSE, RMSE, MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5339fa5c",
   "metadata": {},
   "source": [
    "elde ettiğimiz sabit ve ağırlığımız var. bua ğırlıklara göre tahminlerde bulunduk. hatalarımıza baktık. bir yerde çok iyiyim bir yerde çok kötüyüm. bu yüzden değerlendiremedim tam anlamıyla genel bir şekilde. ortalamasını aldım bu yüzden. şu anda da çok kritik bir yerdeyim mse fonksiyonunun neden karesi var sorusundayım? çünkü eğer burada bir ortalam alırsak artılar eksiler birbirini götüreceğinden dolayı ortlaması 0 olabilir. dolayısıyla 0 olursa hatalarımı ölçemem. bu yüzden mse yönteminde gerçek değerler ile tahmin edilen değerlerin farkını aldıktan sonra karelerini alır. bu sayede yaşanabilecek ölçüm problemini ortadan kaldırmaktadır bu yüzden karesini alıyoruz. burada mse değeri 1. olarak başarı değerlendirme metriği olarak mse değeri ikinci olarak ise optimizasyon problemi olarak mse değeridir. ancak kare alma işleminin bir yan etkisi bulunmaktadır, hatalarımı çok şişirmektedir. 20 olan hatam 400 olmaktadır.\n",
    "\n",
    "Başka metrik olarak ise RMSE değeri vardır. hata kareler ortalamasının kareköküdür. mse de olan şişmenin daha doğru değerlendirilme çabasıdır. karekökünü aldığımda kare almanın tersine döndürmüş oluyorum çünkü.\n",
    "\n",
    "Başka bir metrik olarak da MAE değeri vardır. karekökü ve akresini almak yerine bu değerlerin mutlak değerlerini almaktadır.\n",
    "\n",
    "KRİTİK soru bir modelleme aşamasında bunların hangisini kullanmamzı gerektiğidir. bu 3nden biri seçilip kullanılmaktadır. 3ü birbiriyle kıyaslanamamaktadır çünkü 3ü de ayrı metriklerdir. biz rmse değerimizi kullanacağız ancak rastgele bir seçimdir bu. \n",
    "diğer bölümde bu mse değerinin optimize edilmesi yani ağırlıklarının bulunması işlemine odaklanacağız"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9772a30",
   "metadata": {},
   "source": [
    "### 4- Parametrelerin Tahmin Edilmesi (Ağırlıkların Bulunması)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f3f4d5",
   "metadata": {},
   "source": [
    "yapacağım işlem bana en küçük hatayı verecek olan sabiti ve ağırlığı bulmaktır.\n",
    "bu durum parametrelerin tahmin edilmesi şeklinde, katsayıların bulunması, ağırlıkların bulunması şeklinde ve tahmincilerin bulunması şeklinde ifade edilebilir. burada amaç mse değerini grafiğimde en küçük hata payıyla yani en doğru sonuçları hata ortlaması en az olacak şekilde seçmeey çalışmaktır. 3d grafikte en uç noktaya en alt noktaya ulaşmaya çalışmaktır. bu şekilde olası kombinasyonları deneyerek hatayı en düşük çıkarmaya çalışıyorum.\n",
    "\n",
    "* Bu ağırlıkları bulmanın ilk yolu Analitik Çözüm: Normal Denklemler Yöntemi(En küçük Kareler Yöntemi)(OLS yöntemi)\n",
    "\n",
    "bu yöntem analitik bir çözümdür matris formatında bir çözümdür. türeve dayalı bir çözümdür. bu yöntem kullanıldığında ortaya çıkacak doğrusal formülasyon üzerinde analitik yorumlar yapılabilir, neden sonuç bağlamında yorumlar yapılabilir. eğer elimizde bir bağımlı bir bağımsız değişken varsa bu durumda iki parametreye göre ayrı ayrı kısmi türevler alınıp 0a eşitlenilir ve bulunması gereken çözülmesi gereken bir matematiksel ifade ortaya çıkar. Burada SSE diye bir şey çıktı karşıma. ancak artık bunlardan korkmama gerek yok çünkü her zaman gerçek değerler ile tahmin edilen değerlerin farkıan yönelik şeyler aramam gerektiğini biliyorum. MSE fonksiyonunu aklıma getirip karşılaştırıyorum. SSE demek de hata kareler toplamıdır. mse gibi ortalama almak yerine bir optimizasyon işlemi olarak toplama işlemi yapmaktadırlar. beta1 ve beta0 a göre kısmi türev alınıp betalar yalnız bırakılmaktadır. ve hesaplama işlemleri yapılır. kısaca incelemek gerekirse bağımsız değişkenin değerlerinden ortalam çıkarılmış, bağımlı değişkenin değerlerinden bağımlı değişkenin ortalamaları çıkarılmmış ve bunlar çarpıldıktan sonra toplanmış, aşağı kısmında ise bağımsız değişkenin değerlerinden bağımsız değişkenin ortalaması çıkarılıp karesi alınarak toplanmış ve üstteki değer alttaki değere bölünmüş bu beta1di, beta0 bulmak için de y bağımlı değişkenin ortalaması ile önce hesapladığım beta1 değeri ile bağımsız değşiken ortalaması çarpılır.\n",
    "\n",
    "\n",
    "çok değişken varsa ne olacak peki? yine SSE ifadesi bulunmaktadır. burada da kısmi türevler alınıp 0 a eşitlenildikten sonra ilgili ağırlıklar(betalar) yalnız bırakıldığında ortaya bir matris çözümü çıkacaktır. bu matris çözüldüğünde tahmin edilen betalar bulunacaktır. yani w1 w2 w3.. wn ifadeleri bulunacaktır.\n",
    "\n",
    "\n",
    "* İkinci yöntem olarak asıl zor olan yöntem optimizasyon yöntemidir(Gradient Descent)\n",
    "\n",
    "hatalarımın minimum olmasını istiyorum bunun da minmum olmasını istiyorum. dolayısıyla ağırlıkları bulmam lazım. bu yönem parametre değerlerini iteratif şekilde değiştirerek çalışmaktadır. beta yerine teta da konabilir. b0 = b =teta0\n",
    "b1 = w = teta1 bunlar teorik gösterimdir.\n",
    "özetle burada güncelleme işlemi yapılmaktadır. eski değerler yerine ilgili ağırlığın yeni değerleri atanmaktadır. örn 1000 kere ağırlıkların değeri değiştirildi ve mse değeri düşüyor mu diye sürekli gözlemlenir ve en düşük gözlem değerini veren optimizasyon değeri seçilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f3955f",
   "metadata": {},
   "source": [
    "### 5- Doğrusal Regresyon için Gradient Descent (Gradient Descent for Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bb260e",
   "metadata": {},
   "source": [
    "makine öğrenmesinden bağımsız olarak bu bir optimizasyon yöntemidir.bu optimizasyon yönteminin amacı bir fonksiyonun minimum hata yapabilecek parametre değerlerini bulmaktır. herhangi türevlenebilir bir fonksiyonun minimum parametrelerini bulmak adına optimize edebilir. bu işlemi şöyle gerçekleştirir ilgili fonksiyonun ilgili parametreye göre kısmı türevini alır ve bu türev sonucuna göre güncelleme işlemi yapar. elde edilen türev yani gradyan değeri ilgili fonksiyonun maksimum artış yönünü verir. dolayısıyla ilgili fonksiyonun maksimum artış yönünü veren gradyanın tersine doğru belirli bir şiddet ile giderek parametrenin eski değerinde değişiklik yaparak her iterasyonda hatanın azalmasını sağlar.\n",
    "\n",
    "gradyanın(yani türevi) negatifi olarak tanımlanan 'en dik iniş' yönünde iteratif olarak parametre değerlerini güncelleyerek ilgili fonksiyonun minmum değerini verebilecek parametreleri bulur.\n",
    "gradyan maksimum artış yönünü verir ve eğer bunun tersine gidilirse ilgili fonksiyonun o parametrelerdeki en çok azalacağı yöne gidilir yani en dik iniş yönüne gidilir. işte bu en dik iniş yönü iteratif olarak parametre değerleri değiştirilerek parametrelerin güncellenmesi için kullanılır. bu parametreler fonksiyonun minimum değerini verebilecek parametrelerdir.\n",
    "\n",
    "* neyi çözmesi beklenir ?\n",
    "\n",
    "belirli parametrelerden oluşan fonksiyonu bu parametrelerin değerleri mantıklı iteratif şekilde değiştirerek cost fonksiyonunu minimum yapmaya çalışır. yani cost fonksiyonunu minimilize edebilecek parametreleri bulmak için kullanılır.\n",
    "mse fonksiyonuna 1/2m eklenmiş. buradaki 1/2 optimizasyon için matematiksel problemleri ilgilendirmektedir sadece.\n",
    "\n",
    "* nasıl optimize edecek?\n",
    "\n",
    "amacımız ağırlığın optimum değerini bulmaya çalışmaktır. en dip noktaya inmektir. elimdeki tetalı fonksiyon kullanılarak optimizaasyon için değerler değiştirilip en uygun yol gösterilir. ilgili tetaların kısmi türevleri hesaplanarak ağırlıkların tersine gidilerek değerler güncellenir. bu duruma update rule denir(güncelleme kuralı)(derste matematiğini anlatıyor). tersine de belirli bir hızda gidilir. burada hızımız öğrenme hızını belirtmektedir. gradyan negatif demek gelecek değerin negatif olacağını yani türevin negatif olacağından bahsetmektedir. eğim pozitifse sola doğru gitmemiz gerekmektedir eğer eğim negatifse sağa doğru gidip azaltmamız gerekmektedir. bu şekilde dibe ulaşılacaktır. yani optimum değere.öğrenme hızım çok yavaş olursa optimum optimum noktayı ulaşamayabilirim veya öğrenme hızım çok hızlı olursa bu seferde optimum noktayı geçebilirim kaçırabilirim. burada öğrenme hızımı belirleyecek şey learningratedir. yani öğrenme hızı derken de hangi aralıklarla işlemi optimize edip eski değerlerle karşılaştırmam gerektiğidir. learning rate öğrenme oranıdır. hızlı olursa local minimum noktası kaçırılabiilr!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d310cf41",
   "metadata": {},
   "source": [
    "### 6- Stacking & Ensemble Learning (ametin bootcamp videoları buraya kadar sonrası miuuya geçtim orada 6. buydu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9d5f1",
   "metadata": {},
   "source": [
    "temeli birden fazla modeli bir arada kullanmaya dayanmaktadır. ensemble learning topluluk öğrenme yöntemi kapsamında birden fazla ağaç yönteminin bir araya gelerek tek bir ağaç gibi, bir meclis gibi hareket ederler ve hepsi tahminlerde bulunmaktadır ve bu tahminler bir aray getirilerek değerlendirilmektedir. tek bir algoritmanın çalışıp işlemleri yapması yerine birdedn fazla modelin bir araya gelip işlemleri yapmasına stacking learning, ensemble learning, meta learning gibi isimlendirilmeler yapılmamktadır. örn knn, random forest, gbm, lightgbm gibi modellerin hepsinin bir aray getirilmesi ve hepsinin birlikte tahminleme yapmasıdır. bir gözlem birimi geldiğinde birlikte tahmin oluştururlar. bu işlem ile tahmin performansının güçlnmesi beklenmektedir. çünkü tüm modeller konuya farklı açılardan yaklaşacağından dolayısıyla modellerin kendince iyi açıklamış olabileceği yönler olabilir. bu yüzden hepsinin gücünü bir araya getirerek tahminde bulunma işleminde bulunacağız. bu işlemin diğer bir adı da votingdir yani oylama demektir. votingin regresyon hali de vardır sınıflandırma hali de vardır. sınıflandırm iççin oylama yapmaktadır.\n",
    "bi soft vot kavramı vardır bir de hard vot kavramı vardır. ön tanımlı değer harddır. hard en fazla olan sınıfı ifade etmektedir. yani diyelim 3 kullandığım model var, 3ne sınıflandırma problemi için fikrini sorduk ve diyelim ki 2 tanesi  1 dedi bir tanesi 0 dedi ve sonra o zaman benim tahmini sonucum 1dir diyebiliyoruz. yani en fazla oyu alan sınıf tahmin edilir burada. soft ise dieğr bir argümandır yani oylamanın soft olmasıdır. bu durumda da sınıf gerçekleşme olasılıkları üzerinden bir oylama yapılır. bizim kullanacak olduğumuz ise hard vottur. yani en çok tahmin edilen sınıfı tahmin olarak ver şeklinde olacak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a1b33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lightgbm in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (4.1.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.11.1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "!pip install lightgbm\n",
    "from lightgbm import LGBMClassifier \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc59222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SADECE EN GEREKLİ OLAN İŞLEMLERİ YAPARAK MODELE SOKUP DENEYECEĞİM\n",
    "dff = pd.read_csv(\"titanic.csv\") # veriyi okuttum\n",
    "dff.dropna(inplace = True) # boş verileri sildim\n",
    "dff =pd.get_dummies(dff, columns = [\"Sex\", \"Embarked\"], drop_first = True) # dropfirst true yaparak label encoda ihtiyaç olmayacak şekilde 2 sınıflıları da binary encod ediyorum \n",
    "y= dff[\"Survived\"] #bağımlı değişkenimi seçtim\n",
    "X = dff.drop([\"PassengerId\", \"Survived\", \"Name\", \"Ticket\", \"Cabin\"], axis = 1) #bağımsız değişkenlerimi seçtim\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 17) # test train diye ayırdım\n",
    "#rf_model = RandomForestClassifier(random_state = 46).fit(X_train, y_train) #modelimi kurdum\n",
    "#y_pred = rf_model.predict(X_test) #tahminlerim\n",
    "#accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cf48323",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = LGBMClassifier(learning_rate=0.01, n_estimators=300)\n",
    "knn_model = KNN(n_neighbors=20) #burada modellerimin parametrelerini ayarladım.\n",
    "rf_model = RF(max_depth=8, max_features=7, min_samples_split=15, n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8595431",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {\n",
    "    'KNN': knn_model,\n",
    "    'RF': rf_model,\n",
    "    'LightGBM': LGBMClassifier(learning_rate=0.01, n_estimators=300)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca79491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_classifier(best_models, X, y):\n",
    "    print(\"Voting Classifier...\")#fonksiyon çağırıldığında raporlama yapılmasını istiyorum çalıştığını görmek için yazdık bunu\n",
    "    voting_clf = VotingClassifier(estimators = [(\"KNN\", best_models[\"KNN\"]),\n",
    "                                               (\"RF\", best_models[\"RF\"]),\n",
    "                                               (\"LightGBM\", best_models[\"LightGBM\"])],\n",
    "                                 voting = \"soft\").fit(X, y) #voting_classifier metodunu getirdim, bu model der ki bana kullanacak olduğun moodelleri söyle ve bu modellere vermek istediğin bir isimlendirme varsa onları söyle der. best_modelsin içinde aslında modeller vardır bu modeller tanımlıdır ve best_models[\"KNN\"] dediğimde istediğim model gelecektir.örn rf yazdığımda random forestin hiper parametre ile optimize edilmiş hali gelecektir. ve sonra voting yöntemi ifade edilmiş ve en son da fit edildiğinde bir voting classifier elde edilmiş olacak\n",
    "    \n",
    "    cv_results = cross_validate(voting_clf, X, y, cv=3, scoring=[\"accuracy\", \"f1\", \"roc_auc\"]) #bu classifierın cross_validation hatasına bakacağım\n",
    "    print(f\"Accuracy: {cv_results['test_accuracy'].mean()}\") # ve 3 metric açısından bunları değerlendirip yazdıracağım\n",
    "    print(f\"F1Scora: {cv_results['test_f1'].mean()}\")\n",
    "    print(f\"ROC_AUC: {cv_results['test_roc_auc'].mean()}\")\n",
    "    return voting_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9da9adcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier...\n",
      "[LightGBM] [Info] Number of positive: 123, number of negative: 60\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 108\n",
      "[LightGBM] [Info] Number of data points in the train set: 183, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.672131 -> initscore=0.717840\n",
      "[LightGBM] [Info] Start training from score 0.717840\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 82, number of negative: 40\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 76\n",
      "[LightGBM] [Info] Number of data points in the train set: 122, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.672131 -> initscore=0.717840\n",
      "[LightGBM] [Info] Start training from score 0.717840\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 82, number of negative: 40\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 79\n",
      "[LightGBM] [Info] Number of data points in the train set: 122, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.672131 -> initscore=0.717840\n",
      "[LightGBM] [Info] Start training from score 0.717840\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 82, number of negative: 40\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 79\n",
      "[LightGBM] [Info] Number of data points in the train set: 122, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.672131 -> initscore=0.717840\n",
      "[LightGBM] [Info] Start training from score 0.717840\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.7431693989071038\n",
      "F1Scora: 0.8201025090887418\n",
      "ROC_AUC: 0.8284552845528456\n"
     ]
    }
   ],
   "source": [
    "voting_clf = voting_classifier(best_models, X, y)\n",
    "\n",
    "\n",
    "# aslında buradakiler hiperparametre optimizasyonundan sonra bir araya getirmeye karar\n",
    "#verdiğim 3 modeldir. ve en iyi sonucu vermesini beklerim.\n",
    "# rf begginge dayalı bir yaklaşım lightgbm boostinge dayalı bir yaklaşım\n",
    "#seçilecek modellerin teorik olarak birbirinden farklı yapıları olması beklenir ki birbirlerinin eksik kalan yerlerini doldurabilsinler.\n",
    "#burada da birbirinden farklı ve başarılı mmodelleri koymuşuz gibi düşünebiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36eaa96",
   "metadata": {},
   "source": [
    "### 6.1- Basit Doğrusal Regresyon Modeli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ff86d",
   "metadata": {},
   "source": [
    "bu bölümde bir sales prediction modeli geliştirilecek yani satış tahin modeli geliştirilecek bu model çeşitli kanallarda yapılan reklam harcamalarına ilişkin bu reklam harcamaları neticesinde ne kadar satış elde edildiğini ifade ediyor. yapacağımız şey de iki değişkenli basit bir regresyon modeli kurmak daha sonra veri setinde bulunan 5 değişken ile model kurmak şeklinde olacak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7713b146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69e92e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.float_format\", lambda x: '%.2f' % x) #virgülden sonra 2 basamak göster ayarı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e68cf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.10</td>\n",
       "      <td>37.80</td>\n",
       "      <td>69.20</td>\n",
       "      <td>22.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.50</td>\n",
       "      <td>39.30</td>\n",
       "      <td>45.10</td>\n",
       "      <td>10.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.20</td>\n",
       "      <td>45.90</td>\n",
       "      <td>69.30</td>\n",
       "      <td>9.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.50</td>\n",
       "      <td>41.30</td>\n",
       "      <td>58.50</td>\n",
       "      <td>18.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.80</td>\n",
       "      <td>10.80</td>\n",
       "      <td>58.40</td>\n",
       "      <td>12.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>38.20</td>\n",
       "      <td>3.70</td>\n",
       "      <td>13.80</td>\n",
       "      <td>7.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>94.20</td>\n",
       "      <td>4.90</td>\n",
       "      <td>8.10</td>\n",
       "      <td>9.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>177.00</td>\n",
       "      <td>9.30</td>\n",
       "      <td>6.40</td>\n",
       "      <td>12.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>283.60</td>\n",
       "      <td>42.00</td>\n",
       "      <td>66.20</td>\n",
       "      <td>25.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>232.10</td>\n",
       "      <td>8.60</td>\n",
       "      <td>8.70</td>\n",
       "      <td>13.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  radio  newspaper  sales\n",
       "0   230.10  37.80      69.20  22.10\n",
       "1    44.50  39.30      45.10  10.40\n",
       "2    17.20  45.90      69.30   9.30\n",
       "3   151.50  41.30      58.50  18.50\n",
       "4   180.80  10.80      58.40  12.90\n",
       "..     ...    ...        ...    ...\n",
       "195  38.20   3.70      13.80   7.60\n",
       "196  94.20   4.90       8.10   9.70\n",
       "197 177.00   9.30       6.40  12.80\n",
       "198 283.60  42.00      66.20  25.50\n",
       "199 232.10   8.60       8.70  13.40\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple linear regressions ile devam ediyoruz\n",
    "df = pd.read_csv(\"advertising.csv\")\n",
    "df\n",
    "#toplam 4 değşikende 3 tanesi bağımsız değişken sales bağımlı değişken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ed6668",
   "metadata": {},
   "source": [
    "burada tv radyo gazete kanallarından ortaya çıkan satışlar gözlemlenmektedir. örn 230 birim tv 37 birim radyo 69 birim gazete harcaması olduğunda 22 birim satış elde ediliyormuş. basit şekilde ilerleyebilmek adına 2 tane değişkeni seçip ilerleyeceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "100c5280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78f3a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfnin içerisinden sadece tv değişkenini ve sadece sales değişkenini alıyorum\n",
    "\n",
    "X = df[[\"TV\"]]\n",
    "y = df[[\"sales\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aa154f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TV\n",
      "0   230.10\n",
      "1    44.50\n",
      "2    17.20\n",
      "3   151.50\n",
      "4   180.80\n",
      "..     ...\n",
      "195  38.20\n",
      "196  94.20\n",
      "197 177.00\n",
      "198 283.60\n",
      "199 232.10\n",
      "\n",
      "[200 rows x 1 columns]      sales\n",
      "0    22.10\n",
      "1    10.40\n",
      "2     9.30\n",
      "3    18.50\n",
      "4    12.90\n",
      "..     ...\n",
      "195   7.60\n",
      "196   9.70\n",
      "197  12.80\n",
      "198  25.50\n",
      "199  13.40\n",
      "\n",
      "[200 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09ed0ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model kurma işlemini gerçekleştiriyorum\n",
    "\n",
    "reg_model = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2816c015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.032593549127693"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model.intercept_[0] # eğer teorik bölümde sabit varlığını hatırlayıp sabiti görmek istersen\n",
    "#ilgili sabiti görmek için modeli getirip .intercept_[0] dersem eğer sabiti görebilirim\n",
    "# interept, sabit, bias, beta = sabit demektir\n",
    "#scikit learn sabir için intercep isimlendirmesini tercih etmiş"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6ba012c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047536640433019764"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tvnin katsayısını getirelim modeli getirip . dediğimde içerisinden bir özellik almak istdiğimi belirtiyorum\n",
    "#nedir o? coefficient(katsayı). scikit learn kütüphanesinde coef yani katsayı denmesi tercih edilmiştir.\n",
    "reg_model.coef_[0] #tek 0 koyarsam array olarak getirdiği için bir sıfır daha eklemem lazım\n",
    "reg_model.coef_[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26d34fd",
   "metadata": {},
   "source": [
    "### 7- Doğrusal Regresyon Tahmin İşlemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91d772b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.163089614080658"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#150 birimlik tv harcaması olsa ne kadar satış olması beklenir? sorusuna cevap arayacağız.\n",
    "\n",
    "#önceki regresyon modelimdeki sabit ve ağırlığ getiriyorum, burada eksik olan ne peki?\n",
    "# 150 eksik çarpı 150 dersek problem çözülmüş olacak.\n",
    "\n",
    "reg_model.intercept_[0] + reg_model.coef_[0][0] * 150\n",
    "\n",
    "#işlemin sonucu gelecek sonuç 14. eğer 150 birimlik tv harcaması olursa bu durumda 14 birimlik\n",
    "# satış olmasını bekliyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e5299c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.800913765637574"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#peki 500 birimlik tv harcaması olursa ne kadar satış olur dersek?\n",
    "\n",
    "reg_model.intercept_[0] + reg_model.coef_[0][0] * 500\n",
    " #sonuç geldi ve 30 birim satış olması beklenir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "796fe5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TV</th>\n",
       "      <td>200.00</td>\n",
       "      <td>147.04</td>\n",
       "      <td>85.85</td>\n",
       "      <td>0.70</td>\n",
       "      <td>74.38</td>\n",
       "      <td>149.75</td>\n",
       "      <td>218.82</td>\n",
       "      <td>296.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radio</th>\n",
       "      <td>200.00</td>\n",
       "      <td>23.26</td>\n",
       "      <td>14.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.97</td>\n",
       "      <td>22.90</td>\n",
       "      <td>36.52</td>\n",
       "      <td>49.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newspaper</th>\n",
       "      <td>200.00</td>\n",
       "      <td>30.55</td>\n",
       "      <td>21.78</td>\n",
       "      <td>0.30</td>\n",
       "      <td>12.75</td>\n",
       "      <td>25.75</td>\n",
       "      <td>45.10</td>\n",
       "      <td>114.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>200.00</td>\n",
       "      <td>14.02</td>\n",
       "      <td>5.22</td>\n",
       "      <td>1.60</td>\n",
       "      <td>10.38</td>\n",
       "      <td>12.90</td>\n",
       "      <td>17.40</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count   mean   std  min   25%    50%    75%    max\n",
       "TV        200.00 147.04 85.85 0.70 74.38 149.75 218.82 296.40\n",
       "radio     200.00  23.26 14.85 0.00  9.97  22.90  36.52  49.60\n",
       "newspaper 200.00  30.55 21.78 0.30 12.75  25.75  45.10 114.00\n",
       "sales     200.00  14.02  5.22 1.60 10.38  12.90  17.40  27.00"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d996ce6",
   "metadata": {},
   "source": [
    "burada gözlendiği üzere tv max olarak 296 götermektedir yani 500 birimlik bir harcama yapılmamış daha önce ancak ben artık bu ilişkiyi modelime öğrettiğim için 500 birim gözlemlenmemiş olsa bile ben bunu modelime sorarak tahmin edebilirim. burada görüldüğü gibi max satışlar da 27 olmasına rağmen ben 30 sonucuna erişebildim. burada özüt öğrenmenin sağlayabileceği faydalardan birini görmüş oluyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08b1f3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# modelin görselleştirilmesi\n",
    "\n",
    "g = sns.regplot(x=X, y=y, scatter_kws={\"color\": \"b\", \"s\":9},\n",
    "               ci=False, color=\"r\") #seaborn içinden regresyon modeli görselleştirmek için kullandığım regplot grafiği\n",
    "#x bağımsız değişken y bağımlı değişken ve scatter_kws ile grafikte kullanacak olduğumuz renkler ifade edilmiş\n",
    "# ve güven aralığı bilgisi false güven aralığı ekleme denilmiş. ve regresyon çizgisinin rengi kırmızı olarak ifade edilmiş.\n",
    "# burada mavi olan da saçılım grafiğin scatterplot grafiğin rengini ifade etmektedir.\n",
    "g.set_title(f\"Model Denklemi: Sales = {round(reg_model.intercept_[0], 2)} + TV*{round(reg_model.coef_[0][0], 2)}\") #grafiğe ana bir başlık ekler, ancak burada başlık eklerken dinamik bir biçimlendirme yapılmış, ilkinde regresyon modelinin sabiti alınmış virgülden sonra 2 basamak al round diyerek de uvarlanılmış. diğeri de aynı işlem\n",
    "g.set_ylabel(\"Satış Sayısı\") # y label başlık\n",
    "g.set_xlabel(\"TV Harcamaları\") #x label başlık\n",
    "plt.xlim(-10, 310) # -10dan 310 a kadar x eksenini görselleştir\n",
    "plt.ylim(bottom=0) # ylimite 0dan başla bilgisi verilmiş ve görsel yazdırılmış\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0efd23e",
   "metadata": {},
   "source": [
    "model sonucunda görselleştirmeye bakarak aralarında gerçekten doğrusal bir ilişki varmış gibi gözüküyor. be nmodelin istediğim bir yerinden soru sorarak artık bir tahmine ulaşabiliyorum.(gerçek değerler maviler, kırmızı ise modeldir, tahmin denklemidir. aslında teorik olarak tahmin edilen değerledir.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b0dafe",
   "metadata": {},
   "source": [
    "### 8- Doğrusal Regresyon Tahmin Başarısı"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f359f",
   "metadata": {},
   "source": [
    "bu bölümde tahmin başarısını edğerlendiriyor olacağız. bunlar için mean_squared_error, mean_absolute_error ve roud mean squared error kullanacağız bir de teori bölümünde görmediğimiz r2 kare istatistiği değerini kullanacağız. elimizdeki bu değerleri kullanarak başarımızı değerlendireceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7da1927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tahmin başarısı\n",
    "\n",
    "# mean squared error der ki bana gerçek değerleri ver ve tahmin edilen değerleri ver der.\n",
    "#ben bunların farklarını alırım ve karelerini alırım ve toplayıp sana ortalama hatanı söylerim der.\n",
    "#fakat bizim elimizde tahmin edilen değerler yok. çünkü bütün gözlemlere yönelik bir tahmin yapmadım.\n",
    "# şunu yapmam lazım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecbb799b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.512652915656757"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = reg_model.predict(X) #bağımsız değişkenleri modele sordum ve y_prede kaydedip y ile y_pred arasındaki farkı göreceğim\n",
    "mean_squared_error(y, y_pred) #ortalama hatamı bana verdi mse ile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ef66e29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sales\n",
      "0    22.10\n",
      "1    10.40\n",
      "2     9.30\n",
      "3    18.50\n",
      "4    12.90\n",
      "..     ...\n",
      "195   7.60\n",
      "196   9.70\n",
      "197  12.80\n",
      "198  25.50\n",
      "199  13.40\n",
      "\n",
      "[200 rows x 1 columns] [[17.97077451]\n",
      " [ 9.14797405]\n",
      " [ 7.85022376]\n",
      " [14.23439457]\n",
      " [15.62721814]\n",
      " [ 7.44616232]\n",
      " [ 9.76595037]\n",
      " [12.74649773]\n",
      " [ 7.44140866]\n",
      " [16.53041431]\n",
      " [10.17476548]\n",
      " [17.23871025]\n",
      " [ 8.16396559]\n",
      " [11.66741599]\n",
      " [16.73482186]\n",
      " [16.32125309]\n",
      " [10.25557777]\n",
      " [20.40940417]\n",
      " [10.32212907]\n",
      " [14.03474068]\n",
      " [17.41459582]\n",
      " [18.31779199]\n",
      " [ 7.6600772 ]\n",
      " [17.88520856]\n",
      " [ 9.99412625]\n",
      " [19.52997632]\n",
      " [13.82557947]\n",
      " [18.44614092]\n",
      " [18.85970969]\n",
      " [10.38868036]\n",
      " [20.95607553]\n",
      " [12.39948025]\n",
      " [11.653155  ]\n",
      " [19.65832525]\n",
      " [11.58185004]\n",
      " [20.85149492]\n",
      " [19.72012288]\n",
      " [10.58358059]\n",
      " [ 9.08142275]\n",
      " [17.87094757]\n",
      " [16.65876324]\n",
      " [15.44657891]\n",
      " [20.98935118]\n",
      " [16.86792445]\n",
      " [ 8.22576322]\n",
      " [15.35625929]\n",
      " [11.2966302 ]\n",
      " [18.43663359]\n",
      " [17.83291826]\n",
      " [10.21279479]\n",
      " [16.53041431]\n",
      " [11.80527225]\n",
      " [17.31952254]\n",
      " [15.71278409]\n",
      " [19.52046899]\n",
      " [16.48763133]\n",
      " [ 7.37961102]\n",
      " [13.50708398]\n",
      " [17.05331735]\n",
      " [17.04856369]\n",
      " [ 9.57580381]\n",
      " [19.45391769]\n",
      " [18.4081116 ]\n",
      " [11.91460652]\n",
      " [13.26464711]\n",
      " [10.31262174]\n",
      " [ 8.52999772]\n",
      " [13.65444756]\n",
      " [18.31779199]\n",
      " [17.3385372 ]\n",
      " [16.49713866]\n",
      " [12.25211667]\n",
      " [ 8.30657551]\n",
      " [13.18383482]\n",
      " [17.17691262]\n",
      " [ 7.83596277]\n",
      " [ 8.33985116]\n",
      " [12.76075872]\n",
      " [ 7.28929141]\n",
      " [12.54684384]\n",
      " [10.66439288]\n",
      " [18.43187992]\n",
      " [10.61210257]\n",
      " [10.28409975]\n",
      " [17.18166628]\n",
      " [16.21667248]\n",
      " [10.65963921]\n",
      " [12.29489965]\n",
      " [11.2300789 ]\n",
      " [12.25211667]\n",
      " [13.41676436]\n",
      " [ 8.39214147]\n",
      " [17.38132017]\n",
      " [18.95953663]\n",
      " [12.13802873]\n",
      " [14.79532693]\n",
      " [16.4258337 ]\n",
      " [15.82211837]\n",
      " [20.80395828]\n",
      " [13.45954734]\n",
      " [17.60474238]\n",
      " [21.12245377]\n",
      " [20.3523602 ]\n",
      " [15.96472829]\n",
      " [18.3558213 ]\n",
      " [13.58789626]\n",
      " [ 8.22100956]\n",
      " [11.32990584]\n",
      " [ 7.65532354]\n",
      " [19.17345152]\n",
      " [17.76636696]\n",
      " [18.52219954]\n",
      " [15.38478127]\n",
      " [16.99627338]\n",
      " [10.74995883]\n",
      " [10.60259525]\n",
      " [13.6496939 ]\n",
      " [10.66439288]\n",
      " [13.00794925]\n",
      " [ 7.95480437]\n",
      " [13.74952084]\n",
      " [ 7.92628239]\n",
      " [17.68080101]\n",
      " [12.88435399]\n",
      " [17.94225253]\n",
      " [11.17778859]\n",
      " [ 7.40337934]\n",
      " [10.84503211]\n",
      " [17.50491544]\n",
      " [ 9.86577732]\n",
      " [ 7.0658692 ]\n",
      " [19.63931059]\n",
      " [ 7.43190133]\n",
      " [17.48114712]\n",
      " [ 8.78669558]\n",
      " [ 9.32861328]\n",
      " [ 8.24953154]\n",
      " [20.04337204]\n",
      " [ 9.07666909]\n",
      " [15.82211837]\n",
      " [10.52178296]\n",
      " [16.2404408 ]\n",
      " [17.51442276]\n",
      " [12.00492614]\n",
      " [11.60561836]\n",
      " [13.7019842 ]\n",
      " [18.44614092]\n",
      " [18.5935045 ]\n",
      " [ 8.83898589]\n",
      " [ 9.15748138]\n",
      " [20.37612852]\n",
      " [12.78452704]\n",
      " [16.4258337 ]\n",
      " [15.17562006]\n",
      " [15.95997462]\n",
      " [ 7.22749377]\n",
      " [11.49628409]\n",
      " [14.15358229]\n",
      " [ 7.58877224]\n",
      " [13.29316909]\n",
      " [15.23266402]\n",
      " [11.10648363]\n",
      " [15.98849661]\n",
      " [14.80483426]\n",
      " [12.60388781]\n",
      " [18.17993573]\n",
      " [ 7.88349941]\n",
      " [16.86317079]\n",
      " [17.2719859 ]\n",
      " [20.54726042]\n",
      " [ 9.40942557]\n",
      " [14.8523709 ]\n",
      " [ 7.9643117 ]\n",
      " [15.0377638 ]\n",
      " [17.60474238]\n",
      " [20.19548929]\n",
      " [18.84069503]\n",
      " [15.12332975]\n",
      " [20.18598196]\n",
      " [14.9046612 ]\n",
      " [14.47683144]\n",
      " [17.41934948]\n",
      " [ 9.70415274]\n",
      " [20.70413134]\n",
      " [19.09739289]\n",
      " [16.77760484]\n",
      " [13.66395489]\n",
      " [16.11684554]\n",
      " [20.62807271]\n",
      " [ 7.92152873]\n",
      " [ 8.91029085]\n",
      " [10.6216099 ]\n",
      " [ 7.85022376]\n",
      " [14.96170517]\n",
      " [14.14882862]\n",
      " [ 8.84849321]\n",
      " [11.51054508]\n",
      " [15.44657891]\n",
      " [20.51398478]\n",
      " [18.06584779]]\n"
     ]
    }
   ],
   "source": [
    "print(y, y_pred) #y_pred tahmin edilen değerler, y ler gerçek değerler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84dc34f",
   "metadata": {},
   "source": [
    "Elimde bir mse değeri var ve ben bunun olabildiğince düşük olamsını istiyorum yani mümkün olduğunca 0a doğru gitmesini istiyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "effadcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales   14.02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean() #ynin ortlamasını aldım. daha sonra standart sapmasına bakıyorum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6b4d999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales   5.22\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.std() # stdsi 5 çıktı yani değerler 9 ile 19 arasında değişiyor diyebilirim\n",
    "#bu durumda elde ettiğim 10 değeri büyük mü küçük mü diye düşünüyorum ve birazcık\n",
    "# büyük olduğu kanaatına varıyorum. yani ortalama hata 1.5 2 gibi olsa daha \n",
    "# iyi olabilir gibi geliyor.\n",
    "#değerin büyüklüğünü nasıl değerlendireceğimi bilmediğim durumlarda bağımlı\n",
    "# değişkenin ortalamsına ve standart sapmasına bakıyorum ve kara veriyorum.\n",
    "# bu problem için ben ortalma 10 birimlik bir hata yapıyorsam bu o kadar da küçük değil\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c131fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2423221486546887"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rmse\n",
    "np.sqrt(mean_squared_error(y, y_pred)) # np karekök fonksiyonunu getirdim ve mse değerinin karekökünü hesapladım\n",
    "# rmse değeri buydu. benim için yine ortalama bir hata metriğiydi bu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fc82ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# istersem tekrar mseyi kullanırım geliştirmeler yapıp tekrar mse değerne bakabilirim.\n",
    "#bir de mae değerine bakalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7265ce7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.549806038927486"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mae mutlak hatadır\n",
    "#bunun daha küçük çıkması daha iyi olduğu anlamına gelmemektedir.\n",
    "#buradaki daha iyi kıyası bu modellerin birbiriyle kıyası değil aynı modelde daha\n",
    "# düşük sonuç elde edilmesiyle olmaktadır. örn değişiklik yaptıktan sonra 2 maenin kıyası\n",
    "#diğer kıyaslamaları çoklu doğrusal regersyonda yapacağız.\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6f1fd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.611875050850071"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R-Kare, son olarak r2 ifadesini değerlendirelim.\n",
    "\n",
    "reg_model.score(X, y) #score metoduyla bunu gerçkeleştiriyoruz. bağımlı ve bağımsızdeğişkenleri girdim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e362693a",
   "metadata": {},
   "source": [
    "* nedir bu r2 metriği?\n",
    "\n",
    "doğrusal regersyon modellerinde modelin başarısına ilişkin çok önemli olan bir metriktir r2 metriği. bu değer şnu ifade eder: veri setindeki bağımsız değişkenlerin bağımlı değişkeni açıklama yüzdesidir. örneğin bu veri setinde bir tane bağımsız değşiken kullandık. tv değişkeninin satış değişkenindeki değişikliği açıklama yüzdesidir. yani bu modelde bağımsız değişkenler bağımlı değişkenin %61ni açılkamıştır şeklinde yorumlanır.\n",
    "\n",
    "* Dikkat\n",
    "\n",
    "1. değişken sayısı arttıkça r2 şişmeye meğillidir. Burada düzeltilmiş r2 değerinin de göz önünde bulundurulması gerekmektedir.\n",
    "\n",
    "2. Biz burada olaylara istatistiki ekonometrik vs şeklinde bakmıyoruz. burada modellerin kat sayıların anlamlılığı, f istatistiği, t istatistiği gibi noramellik varsayımı ve diğer bazı varsayımlar gibi varsayımlarla özetle istatistiki çıktılarla ilgilenmiyoruz. bu önemli bir ayrım noktasıdır.buraad model anlamlılıkları veya katsayı testleri yapmıyoruz. burada konuya makine öğrenmesi açısından yaklaşıyoruz. diğer ele alacağımız konularla uyumlu olabilecek bir pencereyle yaklaşıyoruz. dolayısıyla bizim için doğrusal bir formda tahmin etme görevi vardır. bu tahmini en yüksek başarıyla elde etmeye çalışıyor olacağız.burada eğer bu bir istatistik dersi olsaydı ve orada doğrusal regersyonnu değerlendiriyor olasydık bu durumda kat sayıların anlamlılıkları, modelin anlamlılıkları ve varsayım testleri ve bu varsayımlar sağlanmadığında ne yapmak lazım nasıl yaklaşmak lazım gibi çözümlerin hepsini ele almak lazımdı. biz daha çok optimizasyon yaklaşımıyla, makine öğrenmesi yaklaşımıyla yüksek tahmin performansıyla ilgileniyoruz. dolayısıyla aslında basit doğrusal regresyonda, çoklu doğrusal regresyonda yüksek tahmin başarlı değerli modeller değildir ama konunun temellerinde olduğu için bu konularla ilgili bir bilgi ediniyoruz. yani en genelinde bizim gelişmiş regersyon problemlerini çözmek için kullanacağımız modeller regresyon modelleri olmayacak. ağaca dayalı regesyon modelleri olacak. doğrusal regersyon modelleri olmayacak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39407f37",
   "metadata": {},
   "source": [
    "### 9- Çoklu Doğrusal Regresyon Modeli (Multiple Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0911a74",
   "metadata": {},
   "source": [
    "Burada diğeri gibi 1 tane değil birden fazla bağımsız değişkenimiz olacak ve bütün veri setini modellemiş olacağız"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15e013d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.10</td>\n",
       "      <td>37.80</td>\n",
       "      <td>69.20</td>\n",
       "      <td>22.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.50</td>\n",
       "      <td>39.30</td>\n",
       "      <td>45.10</td>\n",
       "      <td>10.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.20</td>\n",
       "      <td>45.90</td>\n",
       "      <td>69.30</td>\n",
       "      <td>9.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.50</td>\n",
       "      <td>41.30</td>\n",
       "      <td>58.50</td>\n",
       "      <td>18.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.80</td>\n",
       "      <td>10.80</td>\n",
       "      <td>58.40</td>\n",
       "      <td>12.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>38.20</td>\n",
       "      <td>3.70</td>\n",
       "      <td>13.80</td>\n",
       "      <td>7.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>94.20</td>\n",
       "      <td>4.90</td>\n",
       "      <td>8.10</td>\n",
       "      <td>9.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>177.00</td>\n",
       "      <td>9.30</td>\n",
       "      <td>6.40</td>\n",
       "      <td>12.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>283.60</td>\n",
       "      <td>42.00</td>\n",
       "      <td>66.20</td>\n",
       "      <td>25.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>232.10</td>\n",
       "      <td>8.60</td>\n",
       "      <td>8.70</td>\n",
       "      <td>13.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  radio  newspaper  sales\n",
       "0   230.10  37.80      69.20  22.10\n",
       "1    44.50  39.30      45.10  10.40\n",
       "2    17.20  45.90      69.30   9.30\n",
       "3   151.50  41.30      58.50  18.50\n",
       "4   180.80  10.80      58.40  12.90\n",
       "..     ...    ...        ...    ...\n",
       "195  38.20   3.70      13.80   7.60\n",
       "196  94.20   4.90       8.10   9.70\n",
       "197 177.00   9.30       6.40  12.80\n",
       "198 283.60  42.00      66.20  25.50\n",
       "199 232.10   8.60       8.70  13.40\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"advertising.csv\")\n",
    "df\n",
    "#burada yapacağımız iş diğer değişkenleri kullanarak çoklu doğrusal regresyon modeli kurmak\n",
    "# olacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48fce1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.10</td>\n",
       "      <td>37.80</td>\n",
       "      <td>69.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.50</td>\n",
       "      <td>39.30</td>\n",
       "      <td>45.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.20</td>\n",
       "      <td>45.90</td>\n",
       "      <td>69.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.50</td>\n",
       "      <td>41.30</td>\n",
       "      <td>58.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.80</td>\n",
       "      <td>10.80</td>\n",
       "      <td>58.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>38.20</td>\n",
       "      <td>3.70</td>\n",
       "      <td>13.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>94.20</td>\n",
       "      <td>4.90</td>\n",
       "      <td>8.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>177.00</td>\n",
       "      <td>9.30</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>283.60</td>\n",
       "      <td>42.00</td>\n",
       "      <td>66.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>232.10</td>\n",
       "      <td>8.60</td>\n",
       "      <td>8.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  radio  newspaper\n",
       "0   230.10  37.80      69.20\n",
       "1    44.50  39.30      45.10\n",
       "2    17.20  45.90      69.30\n",
       "3   151.50  41.30      58.50\n",
       "4   180.80  10.80      58.40\n",
       "..     ...    ...        ...\n",
       "195  38.20   3.70      13.80\n",
       "196  94.20   4.90       8.10\n",
       "197 177.00   9.30       6.40\n",
       "198 283.60  42.00      66.20\n",
       "199 232.10   8.60       8.70\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bunu için sales bağımlı değişkenimi attığım diğer bağımsız değişkenlerimi seçiyorum\n",
    "\n",
    "X = df.drop(\"sales\", axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16d71068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>7.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>9.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>12.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>25.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>13.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sales\n",
       "0    22.10\n",
       "1    10.40\n",
       "2     9.30\n",
       "3    18.50\n",
       "4    12.90\n",
       "..     ...\n",
       "195   7.60\n",
       "196   9.70\n",
       "197  12.80\n",
       "198  25.50\n",
       "199  13.40\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[[\"sales\"]] #bağımlı değişkenimi de dfin içerisinden salesi seçtiğimde seçmiş olacağım.\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba51911",
   "metadata": {},
   "source": [
    "Elimde artık bağımlı ve bağımsız değişkenler var buradan artık model kurma basamağına ilerleyebilirim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225a728",
   "metadata": {},
   "source": [
    "* Model\n",
    "\n",
    " bir önceki bölümde akla şöyle bir soru gelmiş olabilir. model validasyon yöntemlerini\n",
    " kullanmadık mı acaba ya da kullanmalı mıydık gibi, evet önceki bölümde bir regresyon \n",
    " sürecini basit regeresyon üzerinden görsel grfik teknik üzerinden basitçe karmaşıklaştırmadan \n",
    " başarıları değerlendirerek tamamladık.Şimdi bu bölümde de diğer kavramlalrı bir araya getiriyor olacağız.\n",
    " modelleme basamağı bu bölümde o yüzden diğerinden daha farklı şekilde ele alınıyor olacak.\n",
    " yani önce ver setini train test diye ayırmamız lazım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f03894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split metodunu getirerek bu işlemi yapabilirim.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 1)\n",
    "# diyorum ki sen bu bağımlı bağımsız değişkenleri al ve benim test size olarak 20ye 80 olarak ayırdığım şekilde ayır.\n",
    "# yani train oranını 80 test oranını 20 şeklinde ayır ve rastgele bir örneklem  oluştur.\n",
    "#buradaki random_state=1 ifadesi ne anlama gelmektedir? eğer benim oluşturduğum train test ayrımmının ile \n",
    "# sizin oluşturduğunuz train test ayrımının aynı olmasını istiyorsanız buraya aynı numaraları yazmanız gerekmektedir.\n",
    "# hangi sayının yazıldığının önemi yok ancak aynı rassallıkta sayılar oluşacağından aynı sonuçlar elde edilecektir.\n",
    "# bu train test metodu bağımlı ve bağımsız değişkeni ayrı ayrı ister ve daha sonra bize train setinde bir x ve train setinden bir\n",
    "# y ve test setinde bir x ve test setinde bir y verir. yani bu isimlendirmeleri ayrı ayrı yapar\n",
    "# çünkü model kurarken xler ve örn train setinde y'yi birlikte kullanacağız yine model kurarken kullandığımız ve öğrendiğimiz verinin\n",
    "# dışında ayrı ayrı test setindeki xe ve test setindeki yye ihtiyacımız olacak. dolayısıyla 4 parçalı şekilde\n",
    "# trainin xi ysi ve testin xi ysi ayrı olacak şekilde bize veriyi parçalamaktadır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d68d0e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #%80 160 gözlem birimi 3 değişken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9667bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape #%80 160 gözlem birimi 1 değişken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "664ef469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape # %20 40 gözlem birimi 3 değişken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc895694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape #%80 40 gözlem birimi 1 değişken bağımlı değişken y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5901d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ne yapacaktık hatırlayalım train seti ile model kuracaktık ve test seti ile \n",
    "# test edecektik. yapalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68d38aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model = LinearRegression()\n",
    "reg_model.fit(X_train, y_train) # reg_model.fit diyerek modeli kurmuş oluyorum\n",
    "#fit içerisine bağımlı ve bağımsız değişkenleri verdim\n",
    "# bu şekilde kullanabileceğim gibi başka şekilde de kullanabilirim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f7c773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg_model = LinearRegression().fit(X_train, y_train) #bunları birlikte de yazabilirim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "491ed675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.90794702])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hemen tahmin etme hata değerlendirme değil de konuyu pekiştirmek amaçlı \n",
    "# önce sabitini getiriyorum\n",
    "\n",
    "# sabit (b - bias)\n",
    "reg_model.intercept_ #sonuna 0 koyarsam sadece sayı yazacak biliyorum bunu : reg_model.intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c26fbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0468431 , 0.17854434, 0.00258619]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coefficients (w - weights) katsayılar\n",
    "#katsayıları getirmke istersek \n",
    "reg_model.coef_\n",
    "#3 tane weight geldi, bir sonraki bölümde bunlarla ilgili sorularımız olacak\n",
    "#ve yanıtlayacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1f75ce",
   "metadata": {},
   "source": [
    "### 10- Çoklu Doğrusal Regresyonda Tahmin İşlemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ca30fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahminleme aşamasında elde ettiğimiz katsayıları kullanarak tahminleme \n",
    "# işlemini gerçekleştireceğiz.\n",
    "\n",
    "# örn soru\n",
    "# aşağdaki gözlem değerlerine göre satışın değeri nedir?\n",
    "\n",
    "#TV: 30\n",
    "# radio: 10\n",
    "# newspaper: 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebb024bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.90794702])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.90 sabitimin katsayısıydı\n",
    "reg_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ac59af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0468431 , 0.17854434, 0.00258619]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight katsayılarımdı 0.0468431 , 0.17854434, 0.00258619\n",
    "reg_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4cefde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ne yapılması lazım ? doğrusal bir formda ilgili gözlem değerlerinin çarpılıp\n",
    "# sabit ile toplanması lazım.(model denklemini yazınız mülakatlarda sorular\n",
    "#klasik bir sorudur)\n",
    "# bu bir regresyon çıktısıdır, makine öğrenmesi işlerinin yoğunlukta olduğu, istatistiksel işlerin\n",
    "#yoğunlukta olduğu bir veri bilimci pozisyonu için bir regresyon çıktısını yorumlama ve bu regresyon çıktısındaki\n",
    "#ağırlıkları ve sabiti kullanarak model denklemini yazabilmek oldukça önemlidir.\n",
    "#1-) burada birinci sorumuz model denklemini yazınız?\n",
    "#2-) bu değerlere göre beklenen satış sayısı nedir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1bf4be2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.20213102"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model denklemi : \n",
    "# sales = 2.90 + (TV) *  0.04 + (radio) * 0.17 + (newspaper) * 0.002\n",
    "\n",
    "#tahmin edilen satışı bu model denklemine göre bulabiliriz:\n",
    "2.90794702 + 30 * 0.0468431 + 10 * 0.17854434 + 40 * 0.00258619"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f6c334c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.202131]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bu ifadeyi fonksiyonel şekilde nasıl yapabilir dersek:\n",
    "# örn bunu bir departmana vereceğiz \n",
    "\n",
    "yeni_veri =[[30], [10], [40]] #örn yeni bir veri oluşturdum \n",
    "\n",
    "yeni_veri =pd.DataFrame(yeni_veri).T #df çevirdim\n",
    "\n",
    "reg_model.predict(yeni_veri) # tahmin et diyorum bağımsız değişkenleri ver dedim bunlara göre bağımlı değişkenin bilgisini tahmin ediyorum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8be16ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.20 bulmuştum ve kendim hesaplarken 5.88 bulmuştum küsüratlardan dolayı \n",
    "#farklı, bu yüzden orjinalleriyle gidip değerleri değiştiriyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "962b9da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelimi kullanarak manuel tahminlerde bulunabiliyorum, modelin görmediği verilerdi\n",
    "# dışarıdan gelen herhangi yeni gözlemlerdi, şimdi tahmin başarımızı değerlendirme\n",
    "# aşamsına geldik "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe93b5b",
   "metadata": {},
   "source": [
    "### 11- Çoklu Doğrusal Regresyonda Tahmin Başarısı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a48b41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahmin Başarısı Değerelendirme\n",
    "\n",
    "# şimdi elimizde bir train ve test seti var hangisinin hatasına bakmalıyız.\n",
    "# yoksa birlikte mi bakmalıyız, ayrı ayrı mı bakmalıyız? Train testi yaptık ancak cross \n",
    "#validation vardı onu da mı bir değerlendirmeliyiz gibi sorular olabilir. bu bölümde bunların\n",
    "# yanıtlarını bulacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f9afba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# öncelikle train hatamı inceleyebilirim, yani bir model kurdum ve bunu train setimin \n",
    "#üzerinde kurdum ancak daha önce o x ve y'yi komple train seti gibi düşünürsek orada da hata hesaplamıştık.\n",
    "# yani dolayısıyla regresyon modelini train setinde bağımlı değişkeni de tahmin edip kenarda saklayabilirim\n",
    "# ve onun hata kareler oratalmasını v kare köküne erişebilirim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1e28f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7369025901470923"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train RMSE\n",
    "y_pred = reg_model.predict(X_train) #yukarıdaki açıklama \n",
    "np.sqrt(mean_squared_error(y_train, y_pred)) # bu bizim train hatamız, hata kareler ortalamsı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da156145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeli train veri seti üzerinden kurdum buun hatasını değerlendirmek için ne\n",
    "# yapacağım, yine otrain setinin gerçek değerleine ve o train setinin tahmin edilen değerlerine \n",
    "# bakmam gerekmektedir. X_trainden sonra bağımlı değişkenime baktım y_train ve y_pred bu sayede hata oranıma eriştim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5c05532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8959372632325174"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train setine ilişkin R2 değeri\n",
    "# bağımsız değişkenlerşn bağımlı değişkeni açıklmaa oranıdır.\n",
    "reg_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a3f961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neredeyse %90a ulaştık daha önce %60 oranlarında olan değere 3 tane yeni değişken eklediğimde\n",
    "# %90lara kadar ulaşan bir r2 değeri elde etmiş oldum.\n",
    "#o zaman buradan şunu anlıyorum iki değişken vardı bunları underfit etmiştik yani iyi \n",
    "# açıklayamıyorduk ve demek ki hatamız da ona göre daha yüksekti ama  yeni değişkenler eklendiğinde\n",
    "# açıklama oranımız yükseldi, henüz test setine bakmadık ancak ama train seti üzerinden bile yükseldi\n",
    "#tek değikenlide hatam 3.24 iken çok değişkenlideki hatam 1.73 e düştü yani çok ciddi bir \n",
    "# iyileştirme elde etmiş oldum. buradan elde ettiğim bilgi çok değişkenli bir yapı\n",
    "# elde ettiğimde açıklama oranında iyileştirme elde etmem oluyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e33d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ancak ben train setiyle model kuracağım test setiyle test edeceğim demiştim.\n",
    "#tabi ben bunu test ederken train hatasına bakmayayım diye bir şey söz konusu değil\n",
    "# bakabilirim.buna baktıkan sonra test setine bakabilirim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9eea5fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4113417558581587"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST -RMSE\n",
    "y_pred = reg_model.predict(X_test) #burada ilk defa train üzerinden kurduğum modele test verisini sorup hatasını elde ediyorum. predict metodu tahmin etmek için kullanılır.ben sana bir test veri seti göndereceğim sen bunu bir değerlendr diyor.hangi seti göndereceksin sorrusuna tets setini gönder diyoruz. x_test seti bağımsız değişkenlerini soruyoruz modele bu sayede y bağımlı değişkenini tahmin edyor.\n",
    "np.sqrt(mean_squared_error(y_test, y_pred)) # bende y bağımlı değişkeninin gerçek değerleri ve tahmin değerleri var rmse değerini alıyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "879471e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train hatam 1.73tü , test hatam ise 1.41 oldu. peki elde ettiğim 1.41 büyük mü küçük mü,\n",
    "# yoksa iyi mi kötü mü nasıl anlayacağım. normalde train hata ile test hata arasında şöyle bir ilişki vardır.\n",
    "#normalde test hatası train hatasından daha yüksek çıkmaktadır dolayısıyla bizim elde ettiğimiz durum\n",
    "# çok güzel bir durum oldu. testin trainden daha düşük çıkması düşük olduğu anlamına geldi.\n",
    "#bu durum beklenti dışıdır ve güzel bir durumdur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24704b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8927605914615384"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test R2 değeri \n",
    "\n",
    "reg_model.score(X_test, y_test) # öncekine oldukça benzer bir değer elde ettim bu da0.89 çıktı\n",
    "#yani bu veri setindeki bağımsız değişkenlerin bağımlı değişkenleri açıklama yüzdesi %90 civarındadır.\n",
    "# yani oldukça yüksek bir oran denebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7538cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peki şimdi bu train test ayrımıydı, nbu tıpkı rmse, mae değerleri gibi model validasyonu söz konusu olduğunda\n",
    "#tercih yapabileceğimiz, altarnatifler arasından tercih yapabileceğimiz bir yöntemdir.\n",
    "#holdout yöntemi, train test olarak ayırdık, train setiyle model kurduk test setiyle\n",
    "#hatamızı değerlendirdik.bunun yerine onk atlı cros validation da yapabilirdik.\n",
    "# şimdi cross validation yönteini ele alacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f251241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6913531708051797"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 Katlı Cross Validation (CV) RMSE\n",
    "\n",
    "np.mean(np.sqrt(-cross_val_score(reg_model,\n",
    "                                 X, y, cv = 10, scoring=\"neg_mean_squared_error\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e19dbe0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.88689808, 1.81595022, 1.44548731, 1.68069713, 1.14139187,\n",
       "       1.31971064, 2.85891276, 1.45399362, 1.7443426 , 1.56614748])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 katlı cvyi görmek için bakıyorum buna bakmak zorunda değilim görüldüğü gibi 10 tane var\n",
    "np.sqrt(-cross_val_score(reg_model,\n",
    "                        X, y, cv = 10, scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c53c4c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross val scoru hesaplattık bunun için içerisine regresyon modelini kullandım,\n",
    "#bütün veri kullanılmış, dikkat gözlem sayım oldukça az, train setei üzerinde kullnamamayı tercih ediyorum.\n",
    "#çünkü 200 tane satır var zaten dolayısıyla 10 katlı çapraz doğrulamayı bütün veri üzerinden \n",
    "# yapıyorum. bu yüzden x ve y'yi olduğu gibi yazdım. cvnin scoru negatif mean squared error, \n",
    "#yani negatif ortalama hatayı veriyor bu yüzden bunu eksiyle çarptık, başına eksi koymuş olduk\n",
    "#önemli ince bir ayrımdır.bunun başına eksi koymasam değerler eksi şekilde gelecekti\n",
    "#eksi hata olmaaycağı için ortlama hatayı bulmak için eksi ile çarptım. bu yüzden önemi yoktur bu probmlem bu \n",
    "# şekilde basit şekilde çözülebiliyor. bu sayede 10 katlı cvde 10 tane çıktı alıyorum\n",
    "#yukarıda görüldüğü gibi.9 parçasıyla model kurduk 1 tanesiyle test ettik bunlaradan ilki 1.88, bir tnaesi çok \n",
    "# yüksek diğeri çok düşük gibi sonuçlar elde ettim. burada çapraz doğrulama yapmanın \n",
    "# ne kadar önemli olduğunu anlıyoruz. dolayısıyla bunların daha sonrasında kareköklerini alırsam\n",
    "#rmse değerleri gelmiş olur.o zaman bunlar madem 10 katın rmse değerleri o zaman bunların ortlamasını alırsak\n",
    "#10 katlı çapraz doğrulamayı rmse değeri açısından gerçekleştirmiş oluruz.\n",
    "# bizim train hatamız 1.73 test hatamız 1.41 10 katlı cv hatamız ise 1.69dur.\n",
    "# yani buradaki hatalardan hangisine güvenmem lazım, ver isetimiz bol olsa çok fazla \n",
    "# fark etmez gibi bir yorum yapabilirdik fakat veri setimiz az olduğundan dolayı 10 katlı\n",
    "#cv yöntemine güvenmek daha doğru olabilir. bunun dışında veri setinin boyutu az 10 parça yerine 5 parça\n",
    "#mı yapsak deyimi geçerli olabilir kontrol edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf2664cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7175247278732086"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.sqrt(-cross_val_score(reg_model,\n",
    "                                 X, y, cv = 5, scoring=\"neg_mean_squared_error\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d339a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ciddi bir fark gözlemleyemedik.\n",
    "# bu şekilde tek değişkenli ve çok değişkenli olacak şekilde regresyon modellerimizi\n",
    "#kurduk, bu regresyon modellerine ilişkin tahmi netme işlemlerini gerçekleştirdik\n",
    "#daha sonra tahmin başarısı dğerlendirme işlemlerini gerçekleştirdik ve bundan sonra bir regresyon kullanam ihtiyacınız olduktan\n",
    "# sonra direkt veri setini okuma, ilgili veri önişleme özellik mühendisliği  işlemlerini yapma\n",
    "#model kurma basamaklarına gelince de modeli kurmadan önce veriyi 80e 20 ayırma ya da komple bütün veriye hata bakma gibi\n",
    "#cross validation yapmak ve daha sonrasında modelleme işlemi ve daha sonra hata değerlendirme işlemlerini yapmak gibi işlemleri gözlemlemiş olduk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a87f7a8",
   "metadata": {},
   "source": [
    "### 12- Gradient Descent ile Doğrusal Regresyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e7d94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Linear Regression with Gradient Descent from Scratch\n",
    "\n",
    "#yapacağımız işlem tamamen kod seviyesinde 0dan iteratif olarak nasıl çalıştığını \n",
    "# anlamak için olacaktır.aslında regresyon kısmını bitirmiştik.\n",
    "# işlemlerimde mse değerini minimuma getirmeye çalışıyordum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a87439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ilk fonksiyonumu tanımlıyorum cost fonksiyonu \n",
    "# cost fonksiyonunun görvi mse değerini hesaplamaktır. bunun için bütün gözlem değerlerini\n",
    "# gezmemiz ve bir sabit ve ağırlık çiftine göre tahmin edilen değerleri hesaplamamız lazım\n",
    "#bu koşullar doğrultusunda fonksiyonuma 4 tane argüman verdim. y bağımlı değişken\n",
    "#b sabit w ağırlık ve x bağımsız değişken şeklinde. bu örneği iki dğeişken üzerinden gerçekleştiriyor olacağız\n",
    "#len y dediğimde gözlem sayısını tutuyoruz. gözlem sayısı bize neden lazım çünkü tüm gözlem birimlerini gezip bunların hatasını hesaplıyor olacağımdan dolayı\n",
    "#dikkat sse gibi bir ifade var sse hata kareler toplamı demektir. dolayısıyla fonksiyondaki hata kareler toplamı bölümünü buraad gerçekleştiriyor olacağız.\n",
    "# daha sonra da bunu m'e bölerek mse hatasını bulmuş olacağız.for ile bütün gözlem birimlerini gez diyorum. 0dan başlayıp m'e kadar.\n",
    "#birinci gözlem birimine gelince örn ne olacak. tüm sabit ve ağırlık birimine göre tahmin edilen y hesaplanacak. ikinci satırda ise gerçek i değerleri\n",
    "# bulunmaktadır. dolayısıyla bu ikisinin farkı alındıktan sonra karesini alırsam ve bunları her iterasyonda sse'ye ekleyecek şekilde düzenlersem\n",
    "#bu durumda toplam hatayı bulmuş oluruz. bunu m'e böldüğümde ortalama hatayı bulmuş olacağım. yani bu durumda mse değerini bulmuş olacağım.\n",
    "#\n",
    "\n",
    "def cost_function(Y,b,w,X):\n",
    "    m = len(Y)\n",
    "    sse = 0\n",
    "    \n",
    "    for i in range(0,m):\n",
    "        y_hat = b + w * X[i]\n",
    "        y = Y[i]\n",
    "        sse += (y_hat - y) ** 2\n",
    "    mse = sse / m\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b051ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#daha sonra oluşturmam gereken update kuralıdır. yani sabit ve ağırlıkların\n",
    "#update edilmesidir. bu fonksiyonumuzun 5 tane argümanı vardır. Bağımlı değişken,\n",
    "#ağırlıklar, bağımsız değişken ve learning ratedir. learning rate öğrenme oranıdır, öğrenme hızıdır, \n",
    "#yani gradientten ne kadarlık bir parça koparılacağı ve bunun ne hızda eski parametreye yansıtılması\n",
    "#gerektiğini ifade ediyor.\n",
    "\n",
    "def update_weights(Y, b, w, X, learning_rate):\n",
    "    m = len(Y)\n",
    "    \n",
    "    b_deriv_sum = 0\n",
    "    w_deriv_sum = 0\n",
    "    \n",
    "    for i in range(0,m):\n",
    "        y_hat = b + w * X[i]\n",
    "        y = Y[i]\n",
    "        b_deriv_sum += (y_hat - y)\n",
    "        w_deriv_sum += (y_hat - y) * X[i]\n",
    "    new_b = b - (learning_rate * 1 / m * b_deriv_sum)\n",
    "    new_w = w - (learning_rate * 1 / m * w_deriv_sum)\n",
    "    return new_b, new_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "572a533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bazı hesaplamam gereken türevler, gradyanlar var.bunları sum diyerek tutuyorum.bütün gözem \n",
    "#birimlerini gezeceğim ve her bir  gözlem birimi için bir işlem yapacağım.ve bu işlemin neticesini sumlarda tutuyor\n",
    "#olacağım.0'dan m'e kadar gözlemlerimi geziyor olacağım. yine tahmin edilen değerlerimi aldım\n",
    "#ve gerçek değerlerim de y ile elimde. dikkar gradient distence teorisinde, özellikle uygulama bölümünde \n",
    "#yine literatüre baktığımızda kafamız karışabilir. bu yüzden bu noktayı ifade etmekte fayda vardır.\n",
    "#şimdi bu bütün gözlem birimleri gezilerek belirli bir ağırlık seti olduğunda, bu bütün\n",
    "# gözlem birimleri gezilerek aslında her bir gözlem birimi için daha düşük hata vermek için \n",
    "#ne taraf gitmem gerektiği sorusu sorulur.bu birinci iterasyonda 1. gözlem biriminin tahmin edilen değerdir.\n",
    "#alt satırda 1. gözlem değerinin gerçek değerler tutuluyor ve alt satırda bakın tahmin edilen değer ile gerçek değerin\n",
    "# farkı alınıp toplam ifadesine eklenmiş ve bu sabit için yapılmış. Ağırlık için de bu şekilde gerçekleştirilmiş\n",
    "#şimdi sabitin kısmi türevi yani b_deriv_sum 'ın kısmi türevi (y_hat - y)'dir. ağırlığın kısmi türevi de eşit olduğu değerdir.\n",
    "#formülasyona baktığımızdaki işlemlerin yapılma aşaması y_hattan başlayıp w_deriv_suma kadar olan alanda \n",
    "#devam etmektedir.bu aşamada tüm gözlem birimlerine nereye gidilmesi gerektiğine dair bir soru sorulmaktadır.ve çıkan sonuçların ortalaması\n",
    "# alınarak nereye gidileceğine karar verilmektedir örn bir gözlem birimi 3 birim sağa giderken diğeri 2 birim sola gidebilir.new_b,w kısımlarında\n",
    "#ortalama alma işlemi gerçekleşir.burası kritik noktalardan biridir. aslında burada yapılan işlem bütün gözlem brimlerine giderek\n",
    "#belirli bir ağırlık çerçevesinde nereye gidilmesi gerektiğine karar vermektir. buna beach gradient distence denir. bir diğer \n",
    "#gradient distence yöntemi stokastik gradient distence yönteminde ise her iterasyonda sadece 1 gözlem birimine gidilir. mini beach bir başka\n",
    "#gradient distence yöntemindeyse 5, 10,100 şekinde farklı sayıda gözlem birimine gidilir. biz şu anda bütün gözlem birimlerine gidiyoruz.\n",
    "#her iterasyon demiştik, şu anda b_deriv_sum da bir iterasyon yok.sadece bir tane ağırlık çifti var veriye soktuğum bu ağırlık çiftini\n",
    "#gözlem birimlerinden geçiriyorum. gözlem birimlerinden geçtikten sonra biri sağa biri sola dedi ya tamam be no zaman\n",
    "# ortalam alarak nereye gideceğimi bulup bu şekilde ifade edebiliyorum. daa sonra bunları belirli bir learing rate ile çarptıktan sonra\n",
    "#ağırlıkların eski değerleri ile işleme sokarak yeni ağırlıkları tespit ediyorum. dolayısıyla burada sadece bir tane iterasyon var. bu iterasyonda \n",
    "#başta belirttiğim b ve w ağırlıkları içindir. dolayısıyla ben bir kere update weighti çalıştırırsam bana bir kere güncelleme yapacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "36312365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diyelimki ağırlıkları bir kere update ettim daha sonra costu çağırıp hatama baktıktan sonra\n",
    "# bir kere daha updeta işlemi yapabilirim gibi devam edebilirim. bu şekilde belirli bir iterasyon sayısında update \n",
    "# etmem lazım. artık train fonksiyonumu yazıp bütün bu işlemleri belirli bir iterasyon adedince yerine getirebilmenin tanımını\n",
    "#yapmam lazım. aşağıda fonksiyonum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "73e2183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train fonksiyonu\n",
    "\n",
    "def train(Y, initial_b, initial_w, X, learning_rate, num_iters):\n",
    "    \n",
    "    print(\"Starting gradient descent at b = {0}, w = {1}, mse = {2}\".format(initial_b, initial_w,\n",
    "                                                                           cost_function(Y, initial_b, initial_w, X)))#ilk hatanın raporlandığı bölüm.\n",
    "    \n",
    "    \n",
    "    b = initial_b #iterasyon sayıları\n",
    "    w = initial_w #iterasyon sayıları\n",
    "    \n",
    "    cost_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        b, w = update_weights(Y, b, w, X, learning_rate)\n",
    "        mse = cost_function(Y, b, w, X)\n",
    "        cost_history.append(mse)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"iter={:d}    b={:.2f}    w={:.4f}    mse{:.4}\".format(i, b, w, mse))\n",
    "            \n",
    "        print(\"After {0} iterations b = {1}, w = {2}, mse = {3}\".format(num_iters, b, w, cost_function(Y, b, w, X)))\n",
    "        return cost_history, b, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d8ea13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train fonksiyonu bütün bu iterasyon süreçlerini göz önünd bulundurarak yapacak\n",
    "#foknsiyona parametre olarak bağımlı değişken Y, çalışmanın başında biizm verecek olduğumuz\n",
    "# ilk ağırlıklar, bağımsız değişken X, learning rate ve num_iters'i verdik, num_iters iterasyon sayısını,\n",
    "# içermektedir.epoc değeri olarak bazı kaynaklarda görebilirsin ancak bu yanlıştır biz şu anda \n",
    "#sinir ağı mimarilerinde değiliz bu yüzden yanlış olur. elimizde olan şey şu anda doğrusal regresyondur.\n",
    "\n",
    "# işlemlere başlamdan öne cost fonksiyonumu çağırıyorum. cost fonksiyonuma bağımlı değişkenimi giriyorum,\n",
    "#bağımsız değişkenimi giriyorum ve verilecek olan başlangıç ağırlıklarını gir ve bunu bana raporla diyorum.\n",
    "#yani gradient descentin başladığı nokta, ağırlıkların ilk değerleri ve bu ağırlıklara karşı ilk ortalama hatam ve\n",
    "#bunları yazdırıp raporluyorum. işe yarıyor mu yaramıyor mu görmek istiyorum.daha sonra b ve w şeklinde girdiğim ağırlıkları\n",
    "#isimlendiriyorum alt satırda. takip etmesi daha kolay olması açısından bu şekilde bir isimlendirme yaptım.\n",
    "#yani biz çalışamnın başında rastgele değerler vereceğim iki tane ağırlık değeri vereceğim. deneye yanıla optimum yere gidecek ya\n",
    "#biz bu ağırlılkarı rastgele vereceğiz, verdikten sonra lışık olduğumuz notasyona geri dönüyorum takip edilebilirlik açısından bu şekilde \n",
    "# isimlendiriyorum. daha sonra cost history diye bir bölümüm var.her iterasyonda hataları hesaplayacağım.10, 100,1000 iterasyon yapma \n",
    "#durumumuz var her iterasyonda bu hataları gözlemleyip bir yerde saklama istiyoruz.bunları da cost history diye bir listeye atacağız.\n",
    "#daha sonra her iterasyonda bunu hareket ettirip optimum noktaya götürecek bölümdeyiz bu bölüm for döngüsü ile başlayan\n",
    "# bölüm. diyelimki 10, 100 , 1000 iterasyon var bakalım ilk iterasyonda neler oluyormuş. birinci iterasyonda update_weightsi çağırıyoruz\n",
    "#şimdi update_weights bizim sana başta verdiğimiz ilk ağırlıklar var sen bu ağırlıkları al ve sen bunları bi güncelle bakalım diyorum.\n",
    "#daha sonra fonksiyona yazdığım parametreleri ve learning rate oranını veriyorum. o da learning rate oranına göre bi güncelleme işlemi yapıyor.\n",
    "#artık yeni iterasyonlarım olduğu için kontrol etmek amacı ile daha sonra cost fonksiyonumu çağırıyorum. ve mse hatama tekrar bakıyorum bir gelşime olup \n",
    "# olmadığını kontrol etmek amacı ile. fonksiyonumu çağırdıktan sonra tekrardan fonksiyona gerekli parametrelerimi veriyorum.\n",
    "#bu sayede mse değerlerim çıkmış oluyor. şu anda birinci iterasyonda ilk ortalama hatam. bu hatayı cost history içerisine \n",
    "#append ile gönderiyorum daha sonrasında. bununla birlikte ilk iterasyon bitmiş oldu. daha sonrasında hala döngünün içerisindeyim ve \n",
    "# bakıyor ifle eğer inin 100e bölümü 0 ise alttaki koşulu çalıştır diyor. ancak ilk iterasyonda olduğum için yani 1 in 100e bölümü 0 olmadığı için \n",
    "#koşul çalışmayacak. yani aslında burası her 100de bir bölümü rapora demektir.bu aşama subjektiftir ben bu aşamalarda raporlama yapmak istedim gibi\n",
    "# düşünülebilir. daha sonra döngü devam ediyor ve 2. iterasyona geldim. dikkat update weightsi birdaha çağırıyorum. sen bu b ve w değerlerini tekrardan al\n",
    "# ve birdaha güncelle bakalım diyorum ve yeni ağırlıklar geliyor. daha sonra yeni ağırlıklara göre costu tekrar çağırıyorum ve yeni ağırlıklara göre yeni hata oranımı \n",
    "#yani mse değerimi tekrardan oluşturuyorum. o da ban sonuç dönüyor ve bunu mse olarak dönüyor. yine bunu döngünün dışındak costun içerisine \n",
    "#gönderiyorum. bu şekilde bunu 10 20, 30 ,100 kere yapıyorum ve her 100e geldiğinde bunu raporluyorum, print ediyorum. printin içerisinde ilgili iter\n",
    "#sayısı şu, ilgili ağırlıkların değerleri bunlar (b,w) ve ortalama hatam bu diyerek raporluyorum. daha sonrasında iterasyon sayısı bittikten sonra \n",
    "#işte şu kadar iterasyon sonrasında ağırlıkların değerleri bunlardır, ortlama hatan da budur diyerek son bir raporlama yapıyorum. daha sonra fonksiyonumda\n",
    "# eğer kullanacak olursam diye cost_historyi ve ağırlıkları return ediyorum. şimdi bunu da çalıştırıyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c9383e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# veri setimi baştan okutuyorum.\n",
    "df = pd.read_csv(\"advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c989bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# değişkenlerimi oluşturuyorum\n",
    "\n",
    "X = df[\"radio\"] #radio olsun dedim\n",
    "Y = df[\"sales\"] #bu zaten bağımlı değişkenim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d392c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#şimdi train fonksiyonumu çalıştıracağım ancak learning rate ne olacak sorum var\n",
    "#başlangıç ağırlıkları ne olacak sorusu var, başlangıç iterasyon sayısı ne olacak soruları var.\n",
    "#şimdi dikkat parametre nedir hiperparametre nedir? parametre modelin veriyi kullanarak veriden hareketle bulduğu değerlerdir.\n",
    "#yani ağırlıklar var ya bu ağırlıklar veri setinden bulunur. hiperparametreler ise veri setinden bulunamayan ve\n",
    "#kullanıcı tarafından ayarlanması gereken parametrelerdir. gelişmiş hiperparametre optimizasyonu konularını\n",
    "#gelişmiş ağaç yöntemleri konusunda ele alıyor olacağız. fakat burada gradient destence yöntemi kullandığımızdan dolayı  kullanıcı \n",
    "# tarafından ayarlanması gereken hiperparametreler sözkonusu. dolayısıyla ucundan dokunmuş olduk. \n",
    "#burada başlangıç learningrat oranı, başlangıç iterasyon sayısı oranı ve başlangıç ağırlık değerlerini bizim kullanıcı olarak\n",
    "# belirtmemiz gerekmektedir. bir lisansüstü sorusu olarak da şu soruya yanıt vermiş oluyoruz. normal denklemler yöntemi ile gradient\n",
    "# descent yöntemi arasında doğrusal regresyon açısından, katsayı bulmak, ağırlık bulmak açısından, ne gibi farklılıklar vardır.\n",
    "#işte olası farklılıklardan biri budur. yani ağırlıları bulma görevim var bunu anlıyoruz. bunu normal denklemler yöntemi ile direkt\n",
    "#analitik şekilde çözdük diğeri bir optimizasyon yöntemiydi sürece dayalı olarak gerçekleşiyordu gradient descent bir diğeri ise \n",
    "# yani yeni tespit ettiğimiz durum ise ayarlanması gereken hiperparametreler vardır. normal denklemler yönteminde böyle bir şey yoktur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "665fbd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#veri setimiz için örnek olabilecek hiperparametre değereleri\n",
    "\n",
    "learning_rate = 0.001 # öğrenme oranı\n",
    "initial_b = 0.001 #başlangıç ağırlıklarım b ve w\n",
    "initial_w = 0.001\n",
    "num_iters = 10000 # iterasyon sayım ise 10bin\n",
    "# nereden biliyorum 0.001 olması gerektiğini? bilmiyorum örnek olarak verdim.\n",
    "# bunları gelişmiş yöntemlerde paramaetre arama uzayında, hiperparametre arama uzayında\n",
    "#ilgili hiperparameter kombinasyonlarını deniyor olacağım. hangisinin daha iyi olabileceğini dneme yanılma yoluyla \n",
    "# gözlemliyor olacağım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "46da24db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent at b = 0.001, w = 0.001, mse = 222.9477491673001\n",
      "iter=0    b=0.01    w=0.3708    mse53.25\n",
      "After 10000 iterations b = 0.014998235999999988, w = 0.37084814670000027, mse = 53.25401123914189\n"
     ]
    }
   ],
   "source": [
    "# train fonksiyonumu getirerek öğrenme işlemimi başlatıyorum\n",
    "\n",
    "cost_history, b, w = train(Y, initial_b, initial_w, X, learning_rate, num_iters)\n",
    "# belirlediğim iterasyon sayısı kadar bir train etme işlemi yapacak.learning rate ve başlangıç değerlerim var."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "00d1a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bana başında bir raporlama yapmasını istemiştim ve bu raporlamayı başlarken yaptı\n",
    "#onun çıktısı böyle değil her iter için ağırlık çiftleri gözüküyor. daha sonrasında \n",
    "# ortalam hataları gözükmektedir. çıktıyı beğenmediği için değişkenlere atadı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "13679869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[53.25401123914189]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "806140dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014998235999999988"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "692207a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37084814670000027"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57de882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adım adım gradient descent yöntemini uyguladım projeme ve adım adım hatanın\n",
    "#düşüyor olması lazımdı.\n",
    "# bu bölüm bonus bir bölüm olduğu için öğrenme motivasyonunu bozmamalı zor\n",
    "#bir konuydu. belirli bir veri setiyle çalıştığı için her veriyle çalışmayabilir\n",
    "#bu sadece bir örnekti. sadece teorik olarak bu süreç nsaıl işliyor onu göstermek \n",
    "#için yapılmıştır. \n",
    "# belirli bir yerden sonra haya düşmemeye başladı ne yapılabilir yeni değişkenler eklenebilir\n",
    "# learning rate ile oynanabilir, ya da diğer değerlerle oynanabilir ancak hata alınabilir onlarda.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
