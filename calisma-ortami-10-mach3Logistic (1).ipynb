{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38a53d98",
   "metadata": {},
   "source": [
    "# 11 Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82ab355",
   "metadata": {},
   "source": [
    "## 3- Lojistik Regresyon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d37ccf2",
   "metadata": {},
   "source": [
    "### 1- Lojistik Regresyon (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3633987",
   "metadata": {},
   "source": [
    "Lojistik regersyonda amaç sınıflandırma problemi için bağımlı ve bapımsız değişkenler arasındaki ilişkiyi doğrusal olarak modellemektir. daha önce doğrusal şekilde modellemeye çalışmıştık şimdi de doğrusal şekilde sınıflandırmaya çalışacağız, bağımlı ve bağımsız değişkenler arasındaki ilişkiyi modellemeye çalışacağız. doğrusal regresyonda lışık olduğumuz bir ifade var burada:\n",
    "\n",
    "z = b + w1x1 + w2x2 + w3x3 + ... + wpxp\n",
    "\n",
    "bu ifade doğrusal regresyonun aynısıdır. bir sabitim var v eçeşitli değişkenlerim için olası aağırlıklarım var. elde ettiğim z değerini formülasyonda e üzerine yerleştirirsem 1. sınıfa at olma olasılıklarını elde ediyor olacağım. yani doğrusal regresyondan ne farkım var. birinci olarak bu aşama farklı. birinci işlem tamamen aynı ancak çıkan sonucu sigmoid fonksiyonunda z olarak gördüğümüz yere yazıyor olacağız. iyi ama neden evet dikkat. örneğin bağımlı değişkenin 1 ve 0lardan oluştuğunu düşünelim, diğer bağımsız değişkenler de çeşitli değerlerden oluşsun. normalde bağımlı değişken 1 ve 0 olduğunda bu modeli kurabiliriz bunda bir problem yok. fakat bu modeli kurduğumuzda tahmin sonuçlarını elde etmek istediğimizde değerler 1den büyük ya da 0dan küçük çıkabilir, eksi değerler çıkabilir dolayısıyla öyle bir işlem yapmam lazım ki tahmin edilen nihai sonuç 0 ile 1 arasında yer alsın ve bunu belirli bir eşik değerine göre 1 ile 0 arasında değerlendirebilelim. bu amacımızı yerine getirmek için böyle bir dönüştürme işlemi yapılıyor. bu fonksiyona sigmoid fonksiyonu denir. bu doğrusal ifadeden gelen değer sigmoid fonksiyonunda yerine yazıldığında bize 0 ile 1 arasında olacak şekilde bir olasılık değeri üretilir. bu olasılık değerine göre 1 ile 0 sınıfının ataması yapılır. temel mantık çalışma prensibi olarak doğrusal regresyona benzemektedir, sadece sonunda bir değer değişti, bir dönüştürme işlemine tabi tutuluyor. z sonucu sigmoid fonksiyonunda yerine yazıldı. peki bu işlem nasıl gerçekleştiriliyor?\n",
    "yani bu konu bir optimizasyon problemi olarak el alındığında bu problem nasıl çözülür ? gerçek değerler ile tahmin edilen değerler arasındaki farklara ilişkin log loss değerini minimum yapabilecek ağırlıkları bularak gerçekleştirilir. Daha önce mse adında bir fonksiyonumuz vardı burada minimum olacak şekilde ağırlıkları buluyorduk. Yine benzer bir amacımız var. log loss fonksiyonu ile minimum olacak şekilde ağırlıkları bulmaya çalışıyoruz. log loss fonksiyonunun detaylarına kapsamlı şekilde giriyor olacağız. (mse, log loss fonksiyonlarına detaylı şekilde bak matematiksel olarak.)\n",
    "özetle doğrusal fonksiyona benzer bir fonksiyonumuz var buradan türeyecek sonucu gidip sigmoid fonksiyonuma yazıyorum ve çeşitli olasılık değerleri elde ediyorum ve bunların üzerinden yorumlamaları sürdürüyorum.\n",
    "\n",
    "Sigmoid fonksiyonu nedir ve dönüştürm işlemlerini nasıl gerçekleştirmektedir?\n",
    "(araştır görsel olarak bi bak.)\n",
    "\n",
    "1 / 1 + e(üzeri -z) bu fonksiyon sigmoid fonksiyonudur.\n",
    "x ekseninde ifade edilen yerler doğrusal denklemden gelecek olan skorlardır, değerlerdir. belirli bir yöntem ile ağırlıkları bulduğumuzu varsayacak olursak bu ağırlıklar yerine konduktan sonra belirli bir gözlem biriminin değerleri geldiğinde yani bağımsız değişken değerleri geldiğinde bu etkileşimden sonra çıkan değer z değeridir. ve sonra değer sigmoid fonksiyonuna sokulur. sigmoid fonksiyonunun karşılığı ise grafikteki mavi çizgidir. ve buradan çıkacak değer 0 ile 1 arasında olacağı için grafikteki çigi de 0 ile 1 arasında gözükmektedir. yani 0 ile 1 arasında 0 ile 1'e yaklaştıkça 0 ile 1'e yakınsamaktadır. yani klasik regresyon yapsaydık ve bağımlı değişken 1 il 0lardan oluşsaydı bu durumda elde edeceğimiz değerlerin 1 ile 0 arasında olması durumu garanti edilemiyor gibi bir durum vardır. öyleyse ben öyle bir fonksiyon kullanayım ki bunun çıktısını 0 ile 1 arasına eşlesin. işte sigmoid fonksiyonunun görevi budur. doğrusal formdan gelen yapı 0 ile 1 arasında dönüştürülür. \n",
    "Şimdi dikkat !! önemli olan kısma geliyoruz y eksenine geliyoruz. yani tahmin edilen değerlere geliyoruz. denklem aşağıdaki gibidir.\n",
    "\n",
    "yi(şapkalı) = P(Y = 1 | X = x) \n",
    "\n",
    "X bağımsız değişkenleri değerlerini aldığında, Y yani bağımlı değişkenin 1. sınıfının gerçekleşmesi olasılığı(P) ile ilgileniriz. yani sigmoid fonksiyonundan bu dönüşüm işlemi yapıldığında ilgilendiğimiz problemde 1 sınıfa artık o her neyse örn hayatta kaldı kalamadı, hasta hasta değil gibi senaryolarda mesela hayatta kalam durumu olsun dolayısıyla bu fonksiyonun ürettiği değer bir olasılık değeridir. mesela 0.78 olsun. iştee bu değer eşittir ilgili problemdeki bir sınıfın gerçekleşmesi olsılığıdır. dolayısıyla çok kritik bir nokta burası. sınıflandırma problemleriyle ilgilenirken aslında elimizde yapacak olduğumuz tahminlerin sonuçları neticesinde bir sınıfa ait olma olsılığı olur. daha sonra bu 1 sınıfına ait olma olsılıklarını biz bir eşik değere göre dönüştürürüz. bu konuyu da daha sonra örnekle prkiştireceğiz.\n",
    "\n",
    "doğrusal regresyon ve lojistik rgresyondaki bu dönüşüm işlmeleri deep learning ve machine learning işlemlerinin temelini oluşturmaktadır. (Taylan Cemgiz(boğaziçi üni hocası bak, pratikte deep learning aslında nested(nestıd) lojistik regresyondur gibi bir ifadesi vardır.))\n",
    "\n",
    "kritik nokta bir eşik değere göre olsı;lık değerini dönüştürmektir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824933ce",
   "metadata": {},
   "source": [
    "* örn soru\n",
    "soru: verilen bias ve weightlere göre aşağıdaki gözlem birimi için 1 sınıfına ait olma olasılığını hesaplayınız.\n",
    "\n",
    "b = 5, w1 = 4, w2 = -4, w3 = 3        x1 = 2, x2 = 3, x3 = 0\n",
    "\n",
    "ipucu: 1 / 1 + e(üzeri -z) , z = b + w1x1 + w2x2 + w3x3 + ... + wpxp\n",
    "\n",
    "\n",
    "cevap: x'ler  gözlem birimidir ve bu gözlem biriminin değerleri var. ve bir yöntem ile bulunan ağırlıklar var. bu ikisini kullanarak bu gözlem biriminin 1 olarak ilgilenilen sınıfa ait olma olasılığını bulacağız. örn bu hayatta kalıp kalmama olabilir. dolayısıyla bu özelliklere sahip kişinin hayatta kalıp kalmama olasılığını bulabiliriz. öncelikle ne yapılması gerekiyor bu z değerinin hesaplanması gerekmektedir. burada yapılması gereken sabitin ve diğer ağırlıkların yerine yazılıp, buradaki gözlem birimi değerlerinin de(x) x1, x2 ,x3 olacak şekilde yerine yazılması gerekiyor ve z değerinin hesaplanması gerekiyor. daha sonra bu değerin bu formülasyonda yazılarak dönüştürülmesi gerekmektedir. \n",
    "çözüm: z = 5 + (4)*2 + (-4)*3 + 3 * (0)\n",
    "z = 1\n",
    "\n",
    "1 / 1 + e(üzeri -1) = 0.731\n",
    "bu sigmoid fonksiyonunda z değeri yerine yazıldığında 0.731 şeklinde bir değer elde edilmiştir. bu şu anlama gelir bu özellikler verildiğinde 1 sınıfına ait olma olsılığı bu gözlem biriminin 0.73'tür. Evet burada bu ağırlıkların bulunması bir farkındalık noktası. bu ağırlıklar bulundu diyeilm buradaki dönüşüm, yani sigmoid fonksiyonu dönüşümüne hakim olunması ayrı bir farkındalık noktası nihayetinde çıkacak olan olasılık değerinin 1 sınıfına iat olma olasılığını bilmek bir diğer ayrı farkındalık noktası daha sonrasında ise bizim elimizdeki gerçek değerler 1 ile 0'larda oluşuyordu ama tahmin ettiğimiz değer bu 0.73 değeri, dolayısıyla gerçek değerlerimiz ile nasıl kıyaslayacağız sorusunun yanıtını biliyor olmak da bir diğer farkındalık noktası, mesela buraya uyarlayacak olursak madem 1 sınıfına ait olma olasılığı 0.731, mesela 0.5 şeklinde bir trashold belirlyelim, eik değer belirleyelim, bu eşil değerlerden yukaraıda olursa 1 sınıfına, eğer altında olursa 0 sınıfının tahmini gibi değerlendirelim. bu durumda 1 sınıfına ait olma olasılığı oldukça yüksek bir olasılıktır. bu mesela 0.20 çıksaydı, 1 sınıfına ait olma olasılığı %20 olacaktı. dolayısıyla bu 0 sınıfı olmalı gibi bir yorumla 0.5i eşik değer olarak kabul edip 0.5'in üzerindeyse 1 aağısındaysa 0 gibi değerlendirerek son bir dönüştürme işlemi yapmış olacağız ve bu dönüştürme işleminde başarılarımızı değerlendirmiş olacağız. diğer bölümde gradient descent kullanarak ağırlıkların bulunması işlemini yapacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa9e24f",
   "metadata": {},
   "source": [
    "### 2- Lojistik Regresyon Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d301bd2",
   "metadata": {},
   "source": [
    "burada yine bir cost fonksiyonumuz var. içerisinde tahmin edilen değerleri ve gerçek değerleri barındırmaktadır.bu problem için cost fonksiyonumuz diğer bir ifadeyle lost fonksiyonumuz loglost ifadesidir.(burada log lost fonksiyonu bulunmaktadır matematiksel olarak araştır.) peki bu fonksiyonda ne var. diyelimki elimizde 100 tane gözlem birimi var. her bir gözlem birimi tek tek gezilerek buradaki hesaplama işlemi gerçekleştirilecek. peki fonksiyonda ne var. diyelimki birinci gözleme gittik toplam sembolünün önündeki ilk y üzeri i değeri birimin gerçek değeri, -1 çarpı sonrasında logaritma var. peki bu logaritmanın içerisinde ne var. dikkat burası önemli burada logun içerisinde bağımlı değişken bulunmaktadır. burada 1 sınıfının gerçekleşme olasılığı vardır. örn 0.80 . y'nin gerçek değeri 1'di dolayısıyla formülün kalan kısmı 0 olacağı için işleme girmeyecek. burada gerçek değerler ile tahmin edilen değerlerin kıyaslanma çabasındayım ama bu kıyaslama çabasını gerçekleştirirken 1 sınıfına ait olma olasılığı olarak tahmin ettiğim, tahmin edebilecek olduğum olasılık değerini logun içerisine koyuyorum ve gerçek değerim ile 1 sınıfına ait olma olasılığının değerini çarpıyorum. bu formülün adı cross entropi formülüdür. entropi ne kadar yüksekse çeşitlilik o kadar fazladır. dolayısıyla entropinin az olmasını çeşitliliğin az olmasını istersiz. peki hangi açıdan. gerçek değer ile tahmin edilen değer açısından. nasıl yani? şimdi 1 sınıfının gerçekleşme olasılığı örnek olarak 0.99 bulunsa bu neredeyse 1 olacaktır. e birin logaritması nedir, 0dır. ayrıca zaten 1 oldığında 1in gerçek değerine oldukça yakın olmuş oluyor. dolayısıyla şunu anlıyorum. 1 sınıfına ait olma olasılığı yani logun içerisindeki değer ne kadar yüksekse formülden türeyecek olan sonuç o kadar düşüktür. loglos fonksiyonu ile ilgili başarı değerlendirme yöntemlerinin sonunda oldukça detaylı ele alacağız. anlayacağımız üzere entropinin düşük olmasını bekliyorum. bu çapraz entropi, cros entrop... mesela birinci gözlem değerin gitmiştim gerçek değer birdi, ikinci gözlem birimine gidelim diyelimki ikinci gözlem değerinin gerçek değeri sıfır. sıfır olunca formülasyonun ilk kısmı gitti bu sefer elimde formülün ikinci kısmı kaldı yani logtan sonraki artı ile başlayan kısım kaldı. ilk olarak 1- 0 buradan bir gelecek, bu durumda elimde 0 sınıfının gerçekleşme olasılığı elimd olsun 0.30 bu durumda formülasyonda 1-0.30 olduğunda yani 1den 1 sınıfının gerçeklşem olasılığını çıkardığımda 0 sınıfının gerçekleşme olasılığı kalmış olur. bu durumda 1 sınıfı için sol taraf, 0 sınıfı için sağ taraf gerçek değer ile tahmin edilen değer arasındaki ölçüme yönelik bir çözüm geliştirilmiş olur. budurumda 1 sınıfının gerçekleşme olasılığı ne kadar küçük olursa, 0 sınıfının gerçekleşme olasılığı o kadar yüksek olacağından az önce 1 sınıfı için yapmış olacağım yani sol taraftaki hesabın aynısı olacaktır ve ortaya şu durum çıkacaktır. sağ taraftaki değer ne kadar büyükse ilgili gözlem birimi ile ilgili sınıf için sağ taraftan çıkacak olan değer o kadar küçük olacaktır(?). dolayısıyla gerçek değerler ile o gerçek değerlerin gerçekleşme olasılıkları ifadeleri birbirlerine ne kadar yakınsa, bu durumda loss değerimiz yani kayıp değerimiz o kadar küçük olacaktır. regresyon problemindeki mse değeri ifadesi gibi düşünelim burada bir logaritmik dönüşüm ile bu işlem gerçkelştirilmiş, elimizde sınıflara ait olma olasılıkları var, sınıfların gerçek değerleri var, dolayısıyla bunun üzerinden entropi hesabı yapılarak bu işlemler toplandıktan sonra ortalaması alınır ve ortalama hata bulunur. evet dikkat belirli bir ağırlık kombinsayonu ile bu sınıflandırma işlemi gerçekleştirildiğinde sınıflandırmay giderken ifade etmiştik ki her zaman 1 sınıfına ait olma olasılığı hesaplanır dolayısıyla bu 1 sınıfına ait olma olasılığı sol tarafta değerlendirilir, 1- bir sınıfına ait olma olasılığı diyerek 0 sınıfına ait olma olasılığı da sağ tarafta değerlendirilerek her bir gözlem birimi için hata hesaplanır, loss hesaplanır, kayıp hesaplanır ve bunlar toplanıp ortalaması alındığında ortalama hata, ortlama kayıp elde edilmiş olur ve bunun düşük olmasını bekleriz. peki bir iterasyonda bu hesaplandı diyelim, gradient descent burada nasıl devreye giriyor? (formül hatırlatması yaptı, gradientin. türevlenebilen ve bir parametreyle şekillenebilen bir fonksiyonu ilgili parametreye göre kısmi türevi alındığında bu kısmi türev belirli bir öğrenme oranı ile çarpılarak ilgili parametrenin eski değerleri ile işleme sokulur(çıkarılır) ve parametrenin değeri güncellenir. bu güncellemeler esnasında hatanın düşmesi beklenir. örneğin bir iterasyonda belirli bir ağırlık serisi sonucunda bir hata elde edilir, daha sonra cost fonksiyonunun ilgili ağırlıklara göre kısmi türevleri alınır bu bir değer verir bize, gelecek olan değerin yönüne göre onun negatifine her koşulda gidilerek parametrenin değeri güncellenir ve böylece bu hataların düşmesi gözlemlenir. bu gradient descent yöntemi lojistik regresyon için sadece burada mı kullanılır, hayır. lojistik regresyon yöntemi için maxismum olabilirlik yöntemiyle de bu parametreler bulunabilmektedir. bizim burada taşımamız gereken farkındalık bu parametrelerin gökten gelmediği ve bir yöntemle bulunması gerektiğidir. bunu ya bazı istatistiki yöntemler ile ya da bazı optimizasyon yöntemleriyle bulabiliriz.) logloss için başaşrı değerlendirme yöntemleri kapsamında bölümü tamamladık işlemlere geçeceğiz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cec04c",
   "metadata": {},
   "source": [
    "### 3- Sınıfladırma Problemlerinde Başarı Değerlendirme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c9c3b",
   "metadata": {},
   "source": [
    "Sınıflandırma problmelerinde başarı mse ile değerlendirliyordu ya darmse değeri ile değerlendiriliyordu. hata kareler ortalamsı ya da hata kareler ortalamasının kare kökü olarak değerlendiriliyordu. burada başarımızı nasıl değerlendireceğiz problemi var. diyelim ki burada bir müşteri terk problemi  sürecindeyiz. bizi terk eden müşteriler  1 ile ifad eedilişş terk etmeyenler 0 ile. öyle bir model kurmak istiyoruz ki müşterilerimizin bizi terk edip terk etmeyeceğini tahmin etmeye çalışalım. dolayısıyla herhangi bir teknik kullanılmış olsun. lojistik regresyon olabilir, ağaca dayalı yöntemler olabilir, yapay sinir ağları olabilir, her hangi bir makine öğrenemsi yöntemi ile bizim elimizdeki veriden öğrendiğimiz yapıyı kullanarak tahminlerimiz olsun. şimdi dikkat burada başarı nedir? 1 olana 1 demektir, 0 olana ise 0 demektir yani burada başarı en az hata payıyla doğru bilebilmektedir. dolayısıyla önümüzdeki tabloda doğru yaptığımız işlemler var 1e 1, 0a 0 demek gibi. bir de geri kalan yanlış yaptığımız işlemler var. şimdi daha öncesinde sayısal değerler vardı bunların farklarını aldık, burada ne yapmamız lazım? hiçbir şey bilmiyor olsak mesela toplamda 7 tane doğru yaptığımız işlem var, 10 tane toplam işlem var, 7/10 diyerek başarı oranımızı veririz öyle değil mi? evet buna accuracy score denir yani doğruluk oranı denir. temelinde bunula ilintili bazı metrikleri görüyor olacağız. \n",
    "\n",
    "* confusion matrix nedir ?\n",
    "yani karmaşıklık matrisi elimizdeki ver issetlerinde henüz modelleme basamağına geçmeden önce ilgilendiğimiz probleme göre 1 ve 0 sınıfları var. az önceki gördüğümüz örnekteki churn, churn değil gibi. ve daha sonra model kurarak bizim tahmin edecek olduğumuz sınıflar var. mesela bir ver isetindeki gerçek değeri 1 olan bazı gözlem birimleri için 1 tahmininde bulunabiliriz. 1 olduğu halde bazıları için 0 tahmininde bulunabiliriz. dolayısıyla 1e 1 dediğimiz noktalarda başarılı, 1 e 0 dediğimiz noktalarda başarısız bir tahmin yapmış oluruz. benzer şekilde veri setinde gerçek sınıfı 0 olanlara 0 diyerek doğru bir işlem, gerçekte sınıfı 0 olanlara 1 diyerek hatalı bir işlem yapmış olabiliriz. dolayısıyla bu matrisi doldurarak tahmin işlemleri gerçekleştirilir. bakalım bunların kesişimlerindeki ifadeler neler? \n",
    "\n",
    "* True Pozitif (TP)\n",
    "doğru işlem yapmak demektir. bunun kılda kalması zor olabiliyor. doğru yapmış olduğumuz işlemlerin başında True ifadesi oluyor. yani 1e 1 işlemi true 0a 0 işlemi true olmaktadır. peki 1e 1 olanlara neden true pozitif denmektedir? pozitif burada 1. sınıfı temsil etmektedir. bu yüzden 1e 1'e true pozitif denir. 0a 0'a true negatif(TN) denir. çünkü negatif 0ı temsil etmektedir. doğru bir işlem yaptığım için true denir.\n",
    "\n",
    "* False Negatif(FN)\n",
    "yanlış işlem yaptığım işlemler içinse false kullanılır. 1 için olduğunda yanlışlık false negatif(FN) kullanılır. 0 için olduğunda ise false pozitif(FP) kullanılır. fn için doğrusu 1 iken tahmin edilen değer olarak 0 dediğimde false negatif oldu. gerçek sınıfı 0 iken tahmin edileni 1 yaptığımda false pozitif oldu. arkadaki negtiflik ibarise de nereye doğru yanlış yaptığımı ifade etmektedir. 1ken 0 dediğimde, 0 negatif olduğu için false negatif olmaktadır.\n",
    "\n",
    "* Accuracy nedir?\n",
    "accuracy doğru sınıflandırma oranıdır. accuracy doğru yaptığımız işlemlerin toplamıdır. nedir onlar? TP ile TN'nin toplamı ve bölü hepsidir. yani:\n",
    "(TP + TN) / (TP + TN + FP + FN)\n",
    "burası sınıflandırma problemlerinin en kritik başlıkarından bir tanesidir. yani hataları doğru deperlendirmektir. çoğu kaynakta accuracy'nin kullanıldığını görürüz ancak accuracynin he rzaman kullanılmaması gerektiğini görmeyiz. dolayısıyla temelleri çok sağlam şekilde atıp ne zaman accuracy ne zaman ondan başka metrikler kullanılması gerektiğini pekiştirmiş olacağız.\n",
    "bunun yanında bir de precision vardır.\n",
    "\n",
    "* Precision nedir?\n",
    "precision pozitif sınıf(1) tahminlerinin başarı oranıdır. bu ne demektir? \n",
    "dikkat! burada taminlerime odaklanıyorum. yani pozitif sınıf tahminlerinin başarı oranıdır. bu ne demek peki? yani True Pozitif / False Pozitif demektir. tahmin ettiklerimde ne kadar baaşrılıyım sorusunun yanıtıdır bu. 1 sınıfı olarak tahmin ettiklerimde ne kadar başarılıyım oranını verir bana.\n",
    "TP / (TP + FP) formülüdür. bunların yanında recall değeri vardır.\n",
    "\n",
    "* Recall değeri nedir?\n",
    "pozitif sınıfın(1) doğru tahmin edilme oranıdır. pozitif sınıf tahminlerinin başarı oranı demiştik yukarıda şimdi de pozitif sınıfın doğru tahmin edilme oranı diyoruz. ikisi farklıdır. burada yukarıda kalan alanı değerlendiriyoruz yani gerçek sınıfı 1 olanları. formülü: TP / (TP + FN)\n",
    "\n",
    "bütün bunlar peki ne demektir?\n",
    "\n",
    "precision diyor ki pozitif sınıf tahminlerinin başarı oranıdır. diğer bir ifadeyle olasılığıdır. tahmin edilen pozitif sınıflarının yani 1 olarak tahmin ettiğimiz sınıfların gerçekte ne kadarının pozitif olduğunu gösterir. örneklendirelim. bir sahtekarlık çalışması üzerinde çalışıyoruz. şidmi sahtekar ile ifade edilen sınıf 1 olsun bu durumda bizim 1 olark tahmin ettiklerimiz ne olacaktır?satekar sınıfı olacaktır. sahtekar olarak tahmin edilenlerin gerçekte ne kadarının sahtekar olduğunu ifade eder. bu metrikte bir işlem sahtekarlık işlemi olmadığı halde sahtekarlık işlemi gibi muamele görebilir. bu işlem tam tersi için de geçrelidir. bu durumda yanlış alarm üretmiş oluruz. dikkat! False pozitif yanlış alarm üretmek demektir. yani hata yaptık sahtekar olmayan birisine sahtekar demiş olduk. bu tabi diğe rkıyaslayaacğımız metriğe göre o kadar da ciddi bir hata değildir. buna istatistikte tip 1 hatası denmektedir. gerçekte sahtekar olamayanlara sahtekara demiş olduk. problem var mı var, problem büyük mü değil. kusura bakma der geçeriz. \n",
    "peki recall nedir? bunu da bir örnk üzerinden ele alalım. pozitif sınıfın doğru tahmin edilme oranıdır. yani gerçekte belirli bir sayıda pozitif  bir sınıf var, burada ilgilendiğimiz senaryo kapsamında sahtekarlık işlemleridir. bu gerçekte sahtekarlık işlemleri olan işlemlerin ne kadarını doğru tahmin ettiğimizi göstermektedir. iyi de bu ne anlama geliyor. önekelendirelim.\n",
    "dikakt! sahtekarlık işlemlerinin ne kadarının doğru tahmin edildiğini tahmin eder.\n",
    "burada sahtekar olduğu halde sahtekar demediklerim var yani recall, sahtekarlık işlemlerinin ne kadarını yakladığımı ifade etmektedir. dolayısıyla bazıları sahtekarlık olduğu halde yakalayamadım. burada artık dah akritik bir durum vardır. sahtekarlık olduğu halde sahtekar diyemediklerimiz var yani false negatif. bu durumda para kaybedilebilir. gözde nkaçırma maliyetidir. ya da örneğin biri hasta iken ona hasta değil demek gibidir. kritik bir hatadır kişinin ölmesine bile sebep olabilir. bu tip 2 hatadır. buna kritik hata denir.\n",
    "peki hocam bunlar nerede işimize yarayacak?\n",
    "eğer elimizdeki sınıflandırma problemi dengeli sınıf dağılıman sahipse accuracy'i verebiliriz. yani doğru sınıflandırma oranı. ancak eğer elimizdeki veri setinde sınıflar dengesiz dağılıyorsa bu durumda direkt accuracy oranını kullanamayız, recall ve precision değerlerine bakmamız gerekmektedir.\n",
    "burada göreceğimiz son metriğimiz de f1 scorudur.\n",
    "\n",
    "* F1 Score nedir?\n",
    "f1 socru precision ve recall değerlerinin harmonik ortalamasıdır. precision değeri tahminlerimizin başarısına odaklanmıştır, recall değeri gerçekleri yakalam başarımıza odaklanmıştır. dolayısıyla ikisi de bizim için önemlidir.\n",
    "bu açıdan f1 scoru ikisininde etkisini tutmaktadır. formülü:\n",
    "f1score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "anlaşılacağı üzere eğer elimzideki veri seti eğer dengeli ise yani sınıfları 1 ve 0'dır. örn %40 e 60 gibi, 45e 55, 50ye 50 gibi birbirine yakınsa çok ciddi bir kayıp yoktur fakat 70e 30,75 25 gibi büyük farklı dağılımlar varsa hele ki 95e 5 vs gibi işte bu durumlarda accuracy kullanmak yanıltıcı olacaktır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b6aa88",
   "metadata": {},
   "source": [
    "### 4- Karmaşıklık Matrisi (Confusion Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4fddff",
   "metadata": {},
   "source": [
    "karmaşılkık matrisi üzerinden birlikte adım adım bir örnek ele alacağız ve başarı değerlendirme metriklerini değerlendiriyor olacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803045a0",
   "metadata": {},
   "source": [
    "soru: 1000 kredi kartı işlemi var. 990 normal işlem. 10 sahtekar işlem.\n",
    "Buna göre Confusion matrisi doldurunuz ve başarı metriklerini hesaplayınız.\n",
    "\n",
    "\n",
    "                                         Tahmin Edilen Sınıf Değeri\n",
    "                                 Fraud İşlem(1)    |       Normal İşlem(0)\n",
    "                     \n",
    "Gerçek Sınıf  | Fraud İşlem(1):           5 +                       5 x   |10\n",
    "Değerleri     | Normal işlem(0):         90                       900    |990\n",
    "                 toplamda                 95                      905         \n",
    "                                          \n",
    "                                          \n",
    "benim bu tabloda verilen değerleri nereye koymam gerektiğini bilmem lazım. bunun için tablonun önce bi dışına koydum. bir model kuruyorum şimdilik ne olduğunun bir önemi yok. kurduğum bu model yardımıyla tahminlerde bulunuyorum. ve örn bu tahminlerin neticesi de şu olsun (5'leri yerleştirdim)\n",
    "5tanesine ben de sahterkarlık işlemi demişim ancak 5 tanesine sahtekarlık değil demişim. yani hatalı bir işlem yapmışım. toplamda 990 tane işlem var ve bu işlemlerin 900 tanesini doğru bilmişim, 90 tanesini yanlış bilmişim. yani 900 tanesini sahtekarlık değil şeklinde başarılı bir şekilde tahmin etmişim.peki diğer 90 tanesine ne demişim, sahtekarlık olmadığı halde sahtekarlık demişim. bu false pozitif hataydı ve kritik bir hata değildi.\n",
    "\n",
    "accuracy oranı nedir = (5 + 900) / 1000 = 0.905 yani %90 accuracyim var.\n",
    "iyi bir oran mı iyi bir oran gibi gözüküyor öyle değil mi? %90 başarılıyım demek. ancak burada dengesiz veri olduğundan dolayı endişeleniyorum.\n",
    "\n",
    "precision değeri nedir = tahmin ettiğim 1 sınıfına ilişkin bir baaşrı metriğiydi. tahmin ettiğim değelerde ne kadar başarılı tahminde bulunduğumu gösteriyordu. yani 5 / (5 +90) = 0.05 yani 1 üzerinden tahmin ettiğim sınıfların ne kadar başarılı olduğunu ne kadar doğru olduğunu gösteriyordu.\n",
    "sonuçlara göre 0.05 neredeee, 0.905 nereeedeee. anlaşılıyor ki benim 1 olarak tahmin ettiğim sınıflardaki bu tahmin başarım zannedildiği kadar iyi değil gibi gözüküyor. \n",
    "\n",
    "recalla bakalım. recall, gerçekteki pozitif sınıfın ne kadarının doğru tahmin edildiğini ifade ediyordu. \n",
    "recall = 5 / (5 + 5) = 0.50 şimdi asıl sorum şu bu model gerçekten başarılı mı? accuracye baktığımda başarılı gibi gözüküyor ama precision ve recall değerlerinde o kadar da başarılı değil gibi gözüküyor. yine dikkatimizi çekecek olacaktır ki precision değeri ana odağımızda olan 1 sınıfındandaki tahminlere göre oluşturulmuşken, recall değeri yine 1 sınıfı var gerçekte, yine bu 1 sınıfını ne kadar doğru tahmin ettiğimi gösteriyor. yani birisi tahminlerin odağında birisi gerçek değerlerin odağında. bunların ikisi de bizim için değerleri. çünkü birisi false pozitif etkiyi tutuyor, diğeri false negatif etkiyi tutuyor. öyleyse bunların ortalamasını alalım.\n",
    "\n",
    "f1 score = 2 * 0.025 / 0.55 = 0.09 bu sınıflandırma problemind ekurmuş olduğumuz model neticesinde elde ettiğimiz sınıf tahminlerini değerlendirdiğimizde accuracye göre bu değerlendirmeyi yapmak çok doğru olmamaktadır. yapılması gerekn şey diğer metriklere bakmaktır. diğer metriklere baktığımızda o kadar da başarılı olmadığımızı görüyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8fd2e3",
   "metadata": {},
   "source": [
    "### 5- Classification Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3fffd1",
   "metadata": {},
   "source": [
    "lojistik fonksiyonunda doğrusal regresyona benzeyen bir yapı vardı. aynısııydı hatta buradan çıkan değeri değerlendirmiyorduk da bunun 0 ile 1 arasında olacağını garanti edecek sigmoid fonksiyonuna gönderiyorduk. ve bu sigmoid fonkiyonu bize bir olasılık değeri türetiyordu. yani ilgili 1 sınıfına ait olma olasılığı üretiyordu. örnek soru üzerinden bakalım. \n",
    "diyelimki müşteri terki tahmini probleminde bir model kurduk bu model neticesinde 1çsınıfa ait olma olasılıklarını bulduk. dikkat! kullandığımız fonksiyonlarda bu olasılık değerlerini görmesek dahi, arka tarafta her zaman 1 sınıfına ait olma olasılığı bulunur. yani siz bir sınıflandırma modeli kurduğunuzda ilgil churn sınıfına burada dahil olma olasılıklarını hesaplarsınız. churn kısmında evet sürekli 1 ve 0 yani tahmin sonucunu görürsünüz. bunun sebebi şudur, ön tanımlı eşik değerlerdir yani örn 0.50 üstündeyse 1 değilse 0 yaz gibi. şimdi buradan hareketle çalışmanın başında belirtilen eşik değere göre eğer 1 sınıfına ait olma olasılığı eğer bu eşik değerinden büyükse bu sınıfı 1 olarak ata denir, bu değerden küçükse 0 ata denir. \n",
    "threshold = eşik değeri ifade ediyordu.\n",
    "\n",
    "accuracy = doğru sınıflandırma sayısı / toplam sınıflandırılan gözlem sayısı\n",
    "\n",
    "örnek: Classification thresold=0.50 ise accuracy nedir?\n",
    "\n",
    "churn       |         Probability of class 1     predict_churn\n",
    "\n",
    "1                                0,80               1 +\n",
    "1                                0,48               0 -\n",
    "0                                0,30               0 +\n",
    "1                                0,45               0 -\n",
    "0                                0,55               1 -\n",
    "1                                0,70               1 +\n",
    "0                                0,42               0 +\n",
    "0                                0,35               0 +\n",
    "1                                0,60               1 +\n",
    "1                                0,70               1 +\n",
    "\n",
    "7/10 = 0.70' dir. accuracy = 0.70'tir.\n",
    "\n",
    "normalde elimde predict churn laybelı yok. hep ait olma olasılığı olan poc1 sınıfı var. bu olasılıklar türediğinde çalışmanın başında belirlenen ve nerdeyse hiçbir zaman değişmeyen %50'dir. ub eşik değere göre tresholdun altında olup olmamasına göre tahminlerde bulunuyorum. dolayısıyla tahmin edilen değerler ile gerçek değerleri şimdi karşılaştırıyorum.\n",
    "\n",
    "\n",
    "\n",
    "peki classification thresoldu 0.75 yaparsak ne olur? şidmi ne yapmamız lazım, yeni thresolda göre sınıf atamaları yapmam lazım yani tahmin değerleri. ve bu sınıf atamaları üzerinden tekrar bir accuracy değeri hesaplamam lazım. burada eşik değer 0.75 olunca sadece en üstteki 1 diğerleri 0 oluyor ancak sonuç burada 0.10 çıkmıyor çünkü daha sonrasında başarılı yaptığım işlemleri saymam gerekmektedir. yani bildiğim sıfırları da sayınca accuracy değerim 5/10 çıkmaktadır yani 0.50'dir. yani classification thresoldu yukarı çekersem her zaman değil belki ama bazen accuracy değerimin düşmesini mi bekleyebiliriz?\n",
    "evet tam olarak bunu beklememiz gerekmektedir. neden düştü? çünkü 1 sınıfına ait olma eşik değeri çünkü bu. eşik değer arttıkça 1 sınıfına dahil olma olasılığım düşmüş olmaktadır. örn 55 1 sınıfına aitti ancak değerimi yükseltince artık sıfır sınıfına ait oldu.\n",
    "\n",
    "\n",
    "peki classification threshold değerimizi = 0.40 yaparsak ne olur? şimdiki accuracy değerime göre işlemimi güncellersem sonuç 0.80 çıkmaktadır. dikkat! treshold değeri değiştikçe accuracy değeri dolaysıyla diğer istatistiki değerler değişiyor olacak. precision, recall, f1 hepsi değişiyor olacak. bu yüzden eşik değerinin değişmesine göre sınıflandırma yani sınıf tahminlerimiz değişmektedir. demek ki öyle bir şey olmalı ki olası bütün eşik değeri değişimleri de göz önünde bulundurularak bir hesaplama yapılsın ve buna göre bir matematiksel ifade karşımıza gelsin öyle değil mi? çalışmalarda ön tanımlı thresold değeri 0.50'dir ancak burada bunu değiştirdikçe değelerim değişmektedir. bu yüzden bu problemi çözmek için ROC Curve(Recevier Operating Characteristic Curve) yöntemi kullanılır. bir diğer sınıflandırma yöntemlerinde başarı değerlendirme yöntemidir. az önceki olası eşik değer değişimlerine karşılık başarı değişimleri nedir sorusuna cevap vermektedir. bu problemi çözmek için roc eğrisi yöntemi kullanılır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff8d211",
   "metadata": {},
   "source": [
    "### 6- ROC Eğrisi (ROC Curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c12bea",
   "metadata": {},
   "source": [
    "sınıflandırma yöntemlerinde başarı değerlendirme yöntemlerine devam ediyoruz. Bununla ilgili bir görsel açtı. TP y ekseninde yer alıyor, FP x eğrisinde yer alıyor. bu görsele roc eğrisi denmektedir. eğer hiçbir model kurulmasaydı ve rastgele 1 ve 0 atamaları yapılsaydı bu durumda tamamen köşeden köşeye uzanana bir çizgi olacaktı yani elde edeceğimiz başarı bu olacaktı. yani burası bir temel karşılaştırma noktasıdır. bu eksenin üzerindeki yeşil mavi turuncu çizgiler yukarıya doğru, yani kapladıkları alan arttıkça başarı oranı artıyor olarak düşünebiliriz. TP ifadesi burada precision ifadesine karşılık gelmektedir, FP'de yanlış alarm üretme oranımızdı. Anlıyorum ki eğriler ne kadar yukarıda o kadar iyi diyebiliyorum. Dikkat burada bu renkli çizgilerin nasıl oluştuğunu anlayacağım. burada örn değerlerim 0 ile 1 arasında dbirthresold değeri alsın. örn bir tanesinde thresoldu 0.1 yaptık, diğerinin 0.5 yaptık, diğerinin 0.75 yaptık. diyelimki 0.1 yaptık ve burada bütün gözlem birimlerinde tahminlerimi oluşturuyorum, birisine 1 diğerine 0 şeklinde. bunun üzerinden karmaşıklık matrisini oluşturuyoruz. bu matrisetn sonra TP rate ile FP rate'e bakıp bunların karşılık geldiği noktayı işaretliyoruz. sonra eşik değeri değiştiriyoruz. örn 0.5 yapıyoruz. bu eşik değerini değiştiridkten sonra tekrar 1 ve 0 şeklinde tahminliyorum. tekrar karmaşıklık matrisini oluşturuyorum. bu matrisi oluşturduktan sonra tekrar TP rate ve FP rate'lere bakıyoruz. hesaplıyoruz bunu. daha sonrasında yine grafiğin üzerinde işaretliyoruz. benzer şekilde olası tüm tresholdları gezip bunların değerlerini buraya işaretlediğimizde roc eğrisi ortaya çıkmaktadır. yani bir problemden bahsettik, bu tresholdları değiştirirsek accuracyler değişiyor dedik ya, o zaman şöylr bir çözüm getirilmiş buna, ben madem olası bütün tresholdları çıkarayım bu olası tresholdlara göre karmaşıklık matrisini oluşturayım. bunun üzerinden her bir olası eşik değerine karşılık TP rate ve FP rate'i hesaplayıp buraya işaretliyorum. bu kadar. yani bizi ttreshold değişikliği kaygısından kurtarmış oldu. Bu grafikte bir eğri ne kadar fazla yer kaplıyorsa ne kadar buraya yakınsa bu o kadar bu modelin başarılı olduğu anlamına gelir. ancak bu eğrilerden bir şey anlamayabilirim. bunu değerlendirmenin yöntemi bu roc eğrisinin altında kalan alanın bir integrali alınırsa bu durumda \"Area Under Curve (AUC)\" metriği elde edilir. yani eğri altında kalan alan auc metriği elde edilir. dikkat auc metriği roc curve'ün uani roc eğrisinin tek bir sayısal değer ile ifade edilişidir. yani roc eğrisinin altında kalan alandır. artık burada yeni bir problemim var. roc eğrisinin altında kalan alanı tek bir sayısal ifade ile nasıl ifade edebilirim problemi. yani tamam o eğrilerin altında kalan alanın hesabı yapılırsa bunu tek bir matematiksel ifade ile temsil edebiliriz. AUC, tüm olası sınıflandırma eşikleri için toplu bir performans ölçüsüdür. demek ki sınıflandırma problemleri söz konusu olduğunda dikkat etmemiz gereken birinci konu sınıf dağılımı dengesiz mi? sorusudur. yani 95 e 5, 90a 10, 85e 15 vs gibi. tabi burada gözden kaçırılmaması gereken nokta %15in burada sayısıdır. bu %15 değeri içerisinde yüz binlerce değer barındırabilir. yani buradaki yüzdeyle beraber içerisinde barındırdığı frekansta önemlidir. tamam birinci dikkat etmemiz gereken konu budur. verim dengeli mi değil mi sorusudur. eğer veri seti dengeli ise yani en azından 75e 25, 65e 35 gibi yoruma açık kıvamdaysa, bir şekilde dengeli yapma çabası hep öntanımlı bir davranış biçimi olmalı ama dengesiz veri diye direkt isimlendirmeyi 95'e 5, 85'e 15 vs gibi durumlarda yapabiliriz. peki eğer veri seti dengesiz ise budurumda recall değerine precision değerine ve bunların harmonik ortalaması olan f1 skoruna bakıyoruz. \"dengeli de olsa dengesiz de olsa buna bakıyoruz.\" çünkü diğer iki durumu da göz önünde bulunduruyor. sadece buna mı bakacağız. bir de AUC'ye bakalım. olası eşik değerlerine karşılık elde edilecek başarı ölçütüdür. dolayısıyla aslında bir sınıflandırma projesi ele aldığımızda auc değerine, racall, precision, f1 score değerlerine ve accuracy değerlerine bakıp yapmış olduğumuz sınıflandırmayle ilgili bir fikir ediniyor olacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9f90bb",
   "metadata": {},
   "source": [
    "### 6- LOG Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafbc26f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
