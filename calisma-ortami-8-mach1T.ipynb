{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d3de8ab",
   "metadata": {},
   "source": [
    "# 11 Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409a910b",
   "metadata": {},
   "source": [
    "## 1 - Temel Kavramlar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818a098a",
   "metadata": {},
   "source": [
    "### 1- Makine Öğrenmesine Giriş (Introduction to Machine Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453557f6",
   "metadata": {},
   "source": [
    "* Temel Kavramlar\n",
    "\n",
    "makine öğrenmesi nedir? bilgisayarların insanlara benzer şekilde öğrenmesini sağlamak maksadıyla çeşitli algoritmalar ve tekniklerin geliştirilmesi için çalışan bilimsel çalışma alanıdır. \n",
    "\n",
    "bu durumu şu şekilde ele alabiliriz. öğrenmenin aşamalalarını incelememiz gerekmektedir. şu soruyla başlayalım.\n",
    "Özellikleri verilen bir evin fiyatını tahmin edebilir miyiz?\n",
    "Örn elimizde basit bir excel tablasu var ve burada evin m2 fiyatı ve fiyatı bulunmaktadır. burada bu tabloya bakarak 80m2 evin fiyatı ne olabilir sorusuna cevap verebiliriz. 80m2 evlerin fiyatlarını incelediğimizde 330bin ile 350bin arasında değiştiğini gözlemlemekteyiz. yani ortalam olarak 340bin tl diyebiliriz. \n",
    "\n",
    "bağımlı değişkeni yani hedeflediğimiz değişkeni sayısal olan değişkenlere regresyon problemi denmektedir. \n",
    "basit regresyon probleminde düz kırmızı olan çizgiye sabit denir ve bunun bir yüksekliği bulunmaktadır bunun bir eğimi bulunmaktadır aynı zamanda baes denir. y = b + wx (b sabit, doğrunun eğimi w, )\n",
    "\n",
    "özellikleri verilen kişilerin haytat kalıp kalamayacağını tahmin edebilir misiniz?\n",
    "bir titanic faciası var? bu veri setinde çeşitli insanlar var bu çeşitli insanların bazı özellikleri var, servived değişkeni de hayatta kalıp kalamama durumunu ifade ediyor. bağımlı değişkendir.(target)\n",
    "bu değişken kategorik değişkendir ve bu değişken 0 ve 1 ile encod edilmiştir.bu durum bir sınıflandırma problemidir. encod edilmesinin sebebi makinelerin anlayacağı şekle çevirmemdir.\n",
    "45 yaşında 3.sınıf erkek bir yolcu hayatta kalabilir mi?(inceledik)\n",
    "burada amacım veriyi gözlemleyip öğrenmek ve yorumlayabilmek.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c92443",
   "metadata": {},
   "source": [
    "### 2- Değişken Türleri (Variable Types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd54b0",
   "metadata": {},
   "source": [
    "üzerinde çalıştığımız problemlere göre değişkenlerin tiplerini tanımamız önemlidir. burada,\n",
    "* sayısal değişkenler (kesikli ve sürekli olabilir.ancak bununla ilgilenmiyorum sayısal olmasıyla ilgileniyorum.)\n",
    "\n",
    "* kategorik değişkenler(nominal(sınıflar arasında fark olmaması örn futbol takımları), ordinal(sınıflar arasında fark olmsaı örn eğitim durumu))\n",
    " ile çalışacağız.\n",
    " \n",
    "makine öğrenmesi çerçevesinde bir de supervised yani denetimli yani gözetimli öğrenme problemlerinde bağımlı değişken(target, dependent, output, response(bunalrın hepsi aynı anlamdadır.)) kavramı vardır. hedef değişkene bağımlı değişkendir. örn hasta olup olmamakla ilgileniyorsak hasta olmak bağımlı değişkendir.\n",
    "\n",
    "bir de bağımsız değişken(feature, independent, input, column, predictor, explanatory=açıklayaıcı değişken(hepsi aynı anlamdadır.)) vardır. bu değişkenleri targeta etki ettiğini varsayıyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dddde8c",
   "metadata": {},
   "source": [
    "### 3- Öğrenme Türleri (Learning Types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d481346",
   "metadata": {},
   "source": [
    "makine öğrenmesi temelinde 3 türle ele alınmaktadır. \n",
    "* denetimli öğrenme(supervised learning)\n",
    "* denetimsiz öğrenme(unsupervised learning)\n",
    "* pekiştirmeli öğrenme(reinforcement learning)\n",
    "\n",
    "pratikte en çok kullılan alan denetimli öğrenmedir.\n",
    "\n",
    "Pekiştirmeli Öğrenmeyi:\n",
    "şöyle düşşünelim; boş bir oda olduğunu düşünelim ve içerisinde bir robot olduğunu düşünelim, bu robotun  bu boş odadan kapıyı kullanarak çıkma görevi olsun. bu robotun yapabileceği olası hamleler nelerdir?\n",
    "bir adım ileri gitmek, bir adım sağa gitmek bir adım sola gitmek belki zıplamak, kolunu kaldırmak gibi  eylemler robotun yapabileceği eylemlerdir. bu robot deneme yanılma yoluyla bu odadan çıkmaya çalışıyor olsun ve başarısız olduğu her girişimle ilgili de cezalandırılıyor olsun, bu şekide deneme yanılma yoluyla yanlış yaptığı şeylerden pekiştire pekiştire, çarpa çarpa örn 3 adım sağa gidip 3 adım sağa gittikten sonra tekrar sağa gitmenin yanlış olduğunu veya tam kapının eşiğine gelince zıplama eylemini yapamayacağı durumunu öğrene öğrene o kapıdan çıkabiliyor olacak. bir çocuğun sobaya dokunup onun yakıyor olduğunu öğrenmesi gibi.\n",
    "\n",
    "Denetimli Öğrenme nedir? :\n",
    "Eğer veri setimizde labellarımız yer alıyorsa bu durumda veri denetimli öğrenme problemine sahiptir. burada örn bir satış durumunda tvden gazeteden radiodan ne kadar satış olduğunu biliyorum bir bağımlılığım var ancak label ifadesi daha çok sınıflandırma problemleri için ifade ediliyor olur. ancak diğer tarafta da burada bir olay var ve bu olayların ortaya çıkardığı bir olay değişkeni var, bir label var şeklinde kodlanabilir. yani eğer veri setimde bir bağımlı değişken varsa bir target varsa bu bir denetimli öğrenme problemidir. burada bağımlı ve bağımsız değişken arasındaki ilişkiyi öğreniyor olur. neden denetimli denir? burada bir yönlendirme var çünkü bak şu şu olduğunda şu olmuş gibi bunun denetiminde şu olmuş gibi. \n",
    "\n",
    "Denetimsiz Öğrenme nedir?\n",
    "ilgili veri setinde labellar yoksa örn churn(müşteri terki oranı) probleminde churn labelının olmadığını düşünelim, yani bağımlı değişken yokken oluşan problemlere denetimsiz, gözetimsiz, unsupervised denir. örn amerikan eyaletlerinin olduğu bir veri seti olsun ve bu eyaletlerin bazı özellikleri verilmişş olsun. ne yapabilirim bu durumda örn eyaletleri segmente edebilirim. nasıl olabilir? burada görülen eyaletlerin gösterdiği özelliklerdeki matematiksel benzerliklere göre kümeleyebilirim. yani sınıflara ayırabilirim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1377f56",
   "metadata": {},
   "source": [
    "### 4- Problem Türleri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e07b993",
   "metadata": {},
   "source": [
    "İlgilendiğimiz makine öğrenmesi problemi regresyon problemimi, bağımlı değişken sayısal mı yoksa sınıflandırma problemimi yani bağımlı değişken kategorik bir değişken mi diye bakarım. eğer elimizdeki bağımlı değişken sayısal bir değişşkense bu durumda regresyon problemiyle ilgileniyor oluruz. Eğer ilgilendiğimiz veri setinde bağımlı değişkenimiz kategorik bir değişken ise sınıflandırma problemimiz var demektir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff2847",
   "metadata": {},
   "source": [
    "### 5- Model Başarı Değerlendirme Yöntemleri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae23539",
   "metadata": {},
   "source": [
    "Bu bölümde tahminlerim ne kadar başarılı sorusuna yanıt arıyor olacağız. örn 22.1 olan değer 20 şeklinde tahmin edilmiş aradaki farkı artık denir, hata denir, kurmuş olduğumuz modeller ile tahminlerde bulunuruz bu modellerde belli sapmalar beklenir, peki bu modellerin başarısını nasıl değerlendiririz? \n",
    "\n",
    "örn kullanılan değerlerden bazıları:\n",
    "* MSE mean squer error: (formülüne bak) hata kareler ortalaması değeridir. bu değeri çok iyi bilmem gerekmektedir. çünkü makine öğrenmesi temellerinde kendine çok önemli bir yer tutmaktadır. hem bir başarı değerlendirme ölçüsüdür hem de optimizason yöntemlerini kullandığımızda daha iyi model kurmak üzere kendisini optimize etmeye çalıştığımız bir fonksiyondur. dolayısıyla bunu çok iyi bilmemiz gerekmektedir. ne işe yarar? kurmuş olduğumuz model neticesindeki y ile yani gerçek değerler ile model arasındaki yani tahmin ettiğimiz değerler ile gerçek değerler arasındaki farkları değerlendirme imkanı sağlar. gerçek(Yi) satış değerleri ile model aracılığı ile tahmin edilen değerlerin(Yi şapka) farkının karelerinin toplamı alınır ve bunların ortalaması alınır. yani hata kareler ortlamasıdır. MSE değeri ne kadar küçükse o kadar iyidir.\n",
    "\n",
    "\n",
    "* RMSE de hata metriği olarak kullanılır ve rmse aynı işlemini kareköke alınmış halidir. hata kareler ortalamsı kareköküdür. yani msedeki kare işleminin geri dönştürme işlemi gibidir.\n",
    "\n",
    "* MAE de mutlak ortalama hatadır. hata metriği olarak kullanılır. gerçek değerler ile tahmin edilen değerlerin farkının mutlak değeri alınır ve toplanıp ortlaması alınır.\n",
    "\n",
    "regresyon modellerinde başarı değerlendirme metrikleri bu şekildedir.\n",
    "\n",
    "\n",
    "Sınıflandırma problemlerinde hata değerlendirme metrikleri;\n",
    "\n",
    "* Accuracy, bir hata değerlendirme ölçütüdür. Doğru işlem yani sınıflandırma sayısı ilel toplam sınıflarılan gözlem sayısı bölümünden elde edilir. yani doğru gözlem / toplam gözlem sonucudur. en bilineni accuracydir. Accuracyde ne kadar yüksekse o kadar iyidir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51285b",
   "metadata": {},
   "source": [
    "### 6- Model Doğrulama (Model Validation) Yöntemleri (sınama seti)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f085b665",
   "metadata": {},
   "source": [
    "Model doğrulamak ne demek? önceki bölümlerlerde elde ettiğimiz hatalar vardı ya örn regresyonda mse değeri gibi işte bu hataları yani modelin başarı oranını daha doğru değerlendirme ve doğruamaya çalışma çabasıdır. Bu ne anlama gelir? eski machine learning dünyasında modelin başarı train edildiği ver isetinde test edilirdi ve bu neden sağlıklı değil olacaksak model zaten veriyi tanıyor bu yüzden aşırı öğrenme gibi problemlerle karşılaşılıyor. bu yüzden modeli train ve test diye ayırıp train kısmıyla eğitmek test kısmıyla da test etmek gerekmektedir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda55c7c",
   "metadata": {},
   "source": [
    "### 7- Model Doğrulama (Model Validation) Yöntemleri K-Katlı Çapraz Doğrulama (K-Fold Cross Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f6a24",
   "metadata": {},
   "source": [
    "orijinal veri seti eğitim ve test diye ikiye ayrıldı eğitim setinde momdel kuruldu yani bağımlı ve bağımsız değişkenler arasındaki ilişki öğrenildi ve daha sonrasında madem bu ilişkiyi öğrendin al bakalım test setindeki bağımsız değişkenlerimi modele sor test verimdeki bağımlı değişkenimi tahmin et sonra bendeki gerçek değerler ile sendeki tahmin dilmiş değerleri kıyaslayalım diyorum.\n",
    "örn elimdeki veri seti kategorik değişkenlerden oluşsun ve 0 ve 1lerden oluşsun. veri setini de 2 parçaya böldüm %80i eğitim seti olsun %20si test verisi olsun. bu bölme işlemi rastgele gerçekleştiriliyor. diyelim ki 20lik kısım veri setinin çok genel olmayan bir kısmını temsil ediyor olsun böyle olursa hata payı beklenenden bir tık daha fazla çıkmış olacaktır. ancak burada 100 gözlemim olduğunu unumuyorum. yani gözlemim az. verim çok olduğunu muhtemleen böyle bir problemim olmayacaktır.\n",
    "\n",
    "k-katlı çapraz doğrulama yöntemi şunu der: beni iki şekilde kullanabilirsiniz, ilk olarak orijinal veriyi 5 parçaya böl 4 parçasıyla model kur 1yle test et der. daha sonra kalan 4 parçayla model kur 1yle test et der. daha sonra bu işlemi kalan parçalar için de yapar ve hataların ortlamasını alarak bir cross validation hata oranı verir. ikinci olarak da önce veriyi train test diye ayırırım daha sonra yukarıda yaptığım işlemleri bu sefer tüm veride değil de sadece eğitim setimde uygularım. 5e böler 4 parçayla model kurar 1yle test eder ve bunu tüm parçalar bitene kadar yapar. buarda hiperparametre optimizasyonları yapılır feature engineering işlemleri yapılır ve en son hiç görmediği veri tekrar girilir. yani ilk ayırdığımız test verisi. yoruma açık olmakla beraber ikinci yöntem genelde daha doğru sonuçlar verebilir, ancak burada verinin binlere gözlemi olması önemlidir. verim bol değilse sorun olabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c62e49c",
   "metadata": {},
   "source": [
    "### 8- Yanlılık - Varyans Değiş Tokuşu (Bias - Variance Tradeoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e335a941",
   "metadata": {},
   "source": [
    "Aşırı öğrenme konusunu değerlendiriyor oalcağız.\n",
    "\n",
    "underfitting = yüksek yanlılık, modelin veriyi az öğrenmesidir. öğrenememesidir. tahmin değerlerini temsil edememektedir. overfittingin karşıtıdır. bazı gözlemlere de çok yakındır yani yanlıdır.\n",
    "\n",
    "doğru model = düşük yanlılık, düşük varyans\n",
    "\n",
    "overfitting = yüksek varyans, aşırı öğrenme, modelin veriyi öğrenmesidir, moedlin veriyi öğrenmemesi gerekmektedir, modelin içindeki örüntüyü öğrenmesi gerekmektedir. yani bağımlı ve bağımsız değişkenler arasındaki ilişkiyi, ilişkinin özütünü çıkarmak demektir, ikişkiyi öğrenmek demektir. yani aşırı öğrenme  modelin veriyi ezberlemesidir.\n",
    "\n",
    "* peki aşırı öğrenmeye düştüğümüzü nasıl anlarız?\n",
    "\n",
    "aşırı öğrenme eğitim setinin ve test setinin model karmaşıklığı ve tahmin hatası çerçevesinde birlikte değerlendirilmesiyle tespit edilebilir. eğitim seti ile test seti birlikte ilerlerken çatallanmalar başladığında grafikte yani ayrı düşmeye başladıklarında aşırı öğrenme gözlemlenmektedir. model karmaşıklığının optimum olduğu noktada eğitimi durdurursak aşırı öğrenmenin önüne geçeriz.\n",
    "\n",
    "model karmaşıklığı nedir sorusunun cevabı ağaç yöntemlerine göre farklı, doğrusal yöntemlere göre farklı, siniri ağlarına göre farklı olacaktır. örn doğrusal yöntemlere göre üstel terimler eklemek yani modeli hassaslaştırmak yani modeli daha detaylı tahminler yapabilir hale getirmek demek olacaktır. yani özelliklerinin kuvvetlendirilmesi olacaktır. ağaç yöntemlerinde ise dallanma sayısını artırmak olabilir. karaşıklaşırma aslında iyi bir şeydir hata oranımızı düşüyor olacaktır ancak bir süre sonra aşırı öğrenmeye girdiğinden çok fazla da karmaşıklaştırmamak lazımdır. buna veriye göre karar verebiliriz.\n",
    "(optimizasyona dayalı ağaç yöntemleri lightgbm gibi gbm gibi mesela lightgbmde iterasyon sayısıdır model karmaşıklığı parametresi, örn 100 iterasyonda iyi sonuç verecektir 1000 iterasyonda daha iyi onuç verecektir ancak 100.000 iterasyonda artık ezberlemeye girecektir.) \n",
    "\n",
    "bu noktada şu olur test seti ve eğitim seti model karmaşıklığı arttığı sürece birlikte grafikte aşağı düşüyor olacaklar, bir miktar hatayı düşürdükten sonra model veriye takıntılı hale gelecek ve eğitim seti düşmeye devam ederken test setindeki hatalar artmaya başlayacaktır çünkü artık verideki ilişkiyi öğrenmek yerine veriyi öğrenmeye başlayacaktır. aşırı öğrenme nasıl çözülebilir? eğitim setinin boyutu artırılabilir, feature selection yapılabilir, ama en nihayetinde gözlemlerde ve değişkenlerde farklılık olmayacağı var sayılırsa eğitim ve test verisinin optimum noktası seçilir ve burada durulur bu sayede aşırı öğrenmenin önüne geçilir\n",
    "\n",
    "mülakatlarda gelebilecek sorulardır..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa23831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
